{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "which: no R in (/opt/slurm/puppet/bin:/opt/slurm/cluster/ibex/install-v2/RedHat-9/bin:/opt/slurm/scripts/bin:/usr/lpp/mmfs/bin:/home/bernaljp/miniconda3/envs/SCH/bin:/opt/slurm/puppet/bin:/opt/slurm/cluster/ibex/install-v2/RedHat-9/bin:/opt/slurm/scripts/bin:/usr/lpp/mmfs/bin:/home/bernaljp/miniconda3/condabin:/opt/slurm/puppet/bin:/usr/share/Modules/bin:/opt/slurm/cluster/ibex/install-v2/RedHat-9/bin:/opt/slurm/scripts/bin:/usr/lpp/mmfs/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/slurm/scripts/bin:/opt/puppetlabs/bin:/home/bernaljp/.local/bin:/home/bernaljp/bin:/opt/slurm/scripts/bin:/home/bernaljp/.local/bin:/home/bernaljp/bin:/opt/slurm/scripts/bin:/home/bernaljp/.local/bin:/home/bernaljp/bin)\n",
      "/home/bernaljp/miniconda3/envs/SCH/lib/python3.11/site-packages/louvain/__init__.py:54: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution, DistributionNotFound\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_cluster_key' from 'scHopfield._utils.io' (/home/bernaljp/packages/scHopfield/scHopfield/_utils/io.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msignal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convolve2d\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspatial\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m squareform\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscHopfield\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msch\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/packages/scHopfield/scHopfield/__init__.py:40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m inference \u001b[38;5;28;01mas\u001b[39;00m inf\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tools \u001b[38;5;28;01mas\u001b[39;00m tl\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plotting \u001b[38;5;28;01mas\u001b[39;00m pl\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamics \u001b[38;5;28;01mas\u001b[39;00m dyn\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Expose key classes and functions at top level\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/packages/scHopfield/scHopfield/plotting/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Plotting module for visualization functions.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01menergy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_energy_landscape, plot_energy_components\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_sigmoid_fit\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnetworks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_interaction_matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/packages/scHopfield/scHopfield/plotting/energy.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manndata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnnData\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_cluster_key\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_energy_landscape\u001b[39m(\n\u001b[32m     12\u001b[39m     adata: AnnData,\n\u001b[32m     13\u001b[39m     cluster: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     **kwargs\n\u001b[32m     17\u001b[39m ) -> plt.Axes:\n\u001b[32m     18\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m    Plot energy landscape on embedding space.\u001b[39;00m\n\u001b[32m     20\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m \u001b[33;03m        Axes with plot\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'get_cluster_key' from 'scHopfield._utils.io' (/home/bernaljp/packages/scHopfield/scHopfield/_utils/io.py)"
     ]
    }
   ],
   "source": [
    "import anndata\n",
    "import celloracle as co\n",
    "import dynamo as dyn\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import scipy as scp\n",
    "from scipy import sparse\n",
    "from scipy.integrate import solve_ivp\n",
    "import scipy.interpolate as interp\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.spatial.distance import squareform\n",
    "import scHopfield as sch\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'figures',\n",
       " 'out',\n",
       " 'dcgm',\n",
       " 'jupyter-server-cpu-04h.sh',\n",
       " 'jupyter-server-cpu-n_hours.sh',\n",
       " 'jupyter-server-gpu-04h.sh',\n",
       " 'jupyter-server-gpu-n_hours.sh',\n",
       " 'spatial_vae_run1',\n",
       " 'mygene_cache',\n",
       " 'spatial_vae_gencode']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data configuration\n",
    "DATA_PATH = '/home/bernaljp/scratch/Data/'  # Update this path\n",
    "DATASET_NAME = 'Hematopoiesis'\n",
    "DATASET_FILE = 'hematopoiesis.h5ad'  # Update filename\n",
    "\n",
    "# Analysis parameters\n",
    "CLUSTER_KEY = 'cell_type'  # Update to your cluster column name\n",
    "VELOCITY_KEY = 'velocity_alpha_minus_gamma_s'\n",
    "SPLICED_KEY = 'M_t'\n",
    "DEGRADATION_KEY = 'gamma'\n",
    "DYNAMIC_GENES_KEY = 'use_for_dynamics'\n",
    "\n",
    "# Order for plotting (update with your cell types)\n",
    "CELL_TYPE_ORDER = ['HSC', 'MEP-like', 'Ery', 'Meg', 'GMP-like', 'Mon', 'Neu', 'Bas']\n",
    "\n",
    "# Network inference parameters\n",
    "N_EPOCHS = 1000\n",
    "BATCH_SIZE = 128\n",
    "W_THRESHOLD = 1e-12\n",
    "SCAFFOLD_REGULARIZATION = 1e-2\n",
    "DEVICE = 'cuda'  # or 'cpu'\n",
    "\n",
    "# Visualization parameters\n",
    "FIGSIZE_LARGE = (15, 10)\n",
    "FIGSIZE_MEDIUM = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Loading data...\n",
      "   Loaded: 1947 cells × 1956 genes\n",
      "   Removing genes with NaN velocities...\n",
      "   After filtering: 1947 cells × 1728 genes\n",
      "   Using 1728 dynamic genes for analysis\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Loading data...\")\n",
    "adata = dyn.read_h5ad(DATA_PATH + DATASET_FILE)\n",
    "print(f\"   Loaded: {adata.n_obs} cells × {adata.n_vars} genes\")\n",
    "\n",
    "# Remove genes with NaN velocities (Hematopoiesis-specific)\n",
    "if DATASET_NAME == 'Hematopoiesis':\n",
    "    print(\"   Removing genes with NaN velocities...\")\n",
    "    bad_genes = np.unique(np.where(np.isnan(adata.layers[VELOCITY_KEY].toarray()))[1])\n",
    "    adata = adata[:, ~np.isin(range(adata.n_vars), bad_genes)]\n",
    "    print(f\"   After filtering: {adata.n_obs} cells × {adata.n_vars} genes\")\n",
    "\n",
    "# Get genes to use for analysis\n",
    "genes_to_use = adata.var[DYNAMIC_GENES_KEY].values\n",
    "n_genes = genes_to_use.sum()\n",
    "print(f\"   Using {n_genes} dynamic genes for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Scaffold from CellOracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Loading CellOracle scaffold...\n",
      "   Scaffold created: 41693 potential connections\n",
      "   TFs: 73, Target genes: 1148\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. Loading CellOracle scaffold...\")\n",
    "base_GRN = co.data.load_mouse_scATAC_atlas_base_GRN()\n",
    "base_GRN.drop(['peak_id'], axis=1, inplace=True)\n",
    "\n",
    "# Create scaffold matrix\n",
    "scaffold = pd.DataFrame(\n",
    "    0,\n",
    "    index=adata.var.index[genes_to_use],\n",
    "    columns=adata.var.index[genes_to_use]\n",
    ")\n",
    "\n",
    "# Convert gene names to lowercase for case-insensitive comparison\n",
    "tfs = list(set(base_GRN.columns.str.lower()) & set(scaffold.index.str.lower()))\n",
    "target_genes = list(set(base_GRN['gene_short_name'].str.lower().values) & set(scaffold.columns.str.lower()))\n",
    "\n",
    "# Map original names for assignment\n",
    "index_map = {gene.lower(): gene for gene in scaffold.index}\n",
    "col_map = {gene.lower(): gene for gene in scaffold.columns}\n",
    "\n",
    "# Fill scaffold with 1s where connections exist\n",
    "for tf in tfs:\n",
    "    tf_original = index_map[tf]\n",
    "    tf_base_GRN = [col for col in base_GRN.columns if col.lower() == tf][0]\n",
    "\n",
    "    for target in base_GRN[base_GRN[tf_base_GRN] == 1]['gene_short_name']:\n",
    "        if target.lower() in target_genes:\n",
    "            target_original = col_map[target.lower()]\n",
    "            scaffold.loc[tf_original, target_original] = 1\n",
    "\n",
    "print(f\"   Scaffold created: {scaffold.sum().sum()} potential connections\")\n",
    "print(f\"   TFs: {len(tfs)}, Target genes: {len(target_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernaljp/packages/scHopfield/scHopfield/_utils/math.py:93: RuntimeWarning: divide by zero encountered in divide\n",
      "  ty = np.log(y / (1 - y))\n",
      "/home/bernaljp/packages/scHopfield/scHopfield/_utils/math.py:93: RuntimeWarning: divide by zero encountered in log\n",
      "  ty = np.log(y / (1 - y))\n"
     ]
    }
   ],
   "source": [
    "sch.pp.fit_all_sigmoids(adata,\n",
    "                         spliced_key=SPLICED_KEY,\n",
    "                         genes=adata.var['use_for_dynamics'].values)\n",
    "\n",
    "sch.pp.compute_sigmoid(adata, spliced_key=SPLICED_KEY, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 1947 × 1728\n",
       "    obs: 'batch', 'time', 'cell_type', 'nGenes', 'nCounts', 'pMito', 'pass_basic_filter', 'new_Size_Factor', 'initial_new_cell_size', 'total_Size_Factor', 'initial_total_cell_size', 'spliced_Size_Factor', 'initial_spliced_cell_size', 'unspliced_Size_Factor', 'initial_unspliced_cell_size', 'Size_Factor', 'initial_cell_size', 'ntr', 'cell_cycle_phase', 'leiden', 'control_point_pca', 'inlier_prob_pca', 'obs_vf_angle_pca', 'pca_ddhodge_div', 'pca_ddhodge_potential', 'acceleration_pca', 'curvature_pca', 'n_counts', 'mt_frac', 'jacobian_det_pca', 'manual_selection', 'divergence_pca', 'curv_leiden', 'curv_louvain', 'SPI1->GATA1_jacobian', 'jacobian', 'umap_ori_leiden', 'umap_ori_louvain', 'umap_ddhodge_div', 'umap_ddhodge_potential', 'curl_umap', 'divergence_umap', 'acceleration_umap', 'control_point_umap_ori', 'inlier_prob_umap_ori', 'obs_vf_angle_umap_ori', 'curvature_umap_ori'\n",
       "    var: 'gene_name', 'gene_id', 'nCells', 'nCounts', 'pass_basic_filter', 'use_for_pca', 'frac', 'ntr', 'time_3_alpha', 'time_3_beta', 'time_3_gamma', 'time_3_half_life', 'time_3_alpha_b', 'time_3_alpha_r2', 'time_3_gamma_b', 'time_3_gamma_r2', 'time_3_gamma_logLL', 'time_3_delta_b', 'time_3_delta_r2', 'time_3_bs', 'time_3_bf', 'time_3_uu0', 'time_3_ul0', 'time_3_su0', 'time_3_sl0', 'time_3_U0', 'time_3_S0', 'time_3_total0', 'time_3_beta_k', 'time_3_gamma_k', 'time_5_alpha', 'time_5_beta', 'time_5_gamma', 'time_5_half_life', 'time_5_alpha_b', 'time_5_alpha_r2', 'time_5_gamma_b', 'time_5_gamma_r2', 'time_5_gamma_logLL', 'time_5_bs', 'time_5_bf', 'time_5_uu0', 'time_5_ul0', 'time_5_su0', 'time_5_sl0', 'time_5_U0', 'time_5_S0', 'time_5_total0', 'time_5_beta_k', 'time_5_gamma_k', 'use_for_dynamics', 'gamma', 'gamma_r2', 'use_for_transition', 'gamma_k', 'gamma_b', 'scHopfield_used', 'sigmoid_threshold', 'sigmoid_exponent', 'sigmoid_offset', 'sigmoid_mse'\n",
       "    uns: 'PCs', 'VecFld_pca', 'VecFld_umap', 'X_umap_neighbors', 'cell_phase_genes', 'cell_type_colors', 'dynamics', 'explained_variance_ratio_', 'feature_selection', 'grid_velocity_pca', 'grid_velocity_umap', 'grid_velocity_umap_ori_perturbation', 'grid_velocity_umap_test', 'jacobian_pca', 'leiden', 'neighbors', 'pca_mean', 'pp', 'response', 'scHopfield'\n",
       "    obsm: 'X', 'X_pca', 'X_pca_SparseVFC', 'X_umap', 'X_umap_SparseVFC', 'X_umap_ori_perturbation', 'X_umap_test', 'acceleration_pca', 'acceleration_umap', 'cell_cycle_scores', 'curvature_pca', 'curvature_umap', 'j_delta_x_perturbation', 'velocity_pca', 'velocity_pca_SparseVFC', 'velocity_umap', 'velocity_umap_SparseVFC', 'velocity_umap_ori_perturbation', 'velocity_umap_test'\n",
       "    layers: 'M_n', 'M_nn', 'M_t', 'M_tn', 'M_tt', 'X_new', 'X_total', 'velocity_alpha_minus_gamma_s'\n",
       "    obsp: 'X_umap_connectivities', 'X_umap_distances', 'connectivities', 'cosine_transition_matrix', 'distances', 'fp_transition_rate', 'moments_con', 'pca_ddhodge', 'perturbation_transition_matrix', 'umap_ddhodge'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring interaction matrix W and bias vector I for cluster Mon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernaljp/packages/scHopfield/scHopfield/inference/optimizer.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mask', torch.tensor(mask, dtype=torch.float32, device=device))\n",
      "Training Epochs:   1%|▏         | 14/1000 [00:01<01:09, 14.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Total Loss: 1510.586029, Reconstruction Loss: 9.965876, Batch size: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 118/1000 [00:02<00:08, 107.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 101/1000] Total Loss: 594.683868, Reconstruction Loss: 0.067412, Batch size: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  22%|██▏       | 222/1000 [00:03<00:06, 121.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 201/1000] Total Loss: 484.379623, Reconstruction Loss: 0.014425, Batch size: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  31%|███▏      | 313/1000 [00:03<00:05, 122.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 301/1000] Total Loss: 443.236977, Reconstruction Loss: 0.003023, Batch size: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  42%|████▏     | 417/1000 [00:04<00:04, 122.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 401/1000] Total Loss: 426.917397, Reconstruction Loss: 0.001454, Batch size: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  52%|█████▏    | 521/1000 [00:05<00:03, 122.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 501/1000] Total Loss: 420.201607, Reconstruction Loss: 0.001309, Batch size: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  62%|██████▎   | 625/1000 [00:06<00:03, 123.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 601/1000] Total Loss: 417.500839, Reconstruction Loss: 0.001312, Batch size: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  72%|███████▏  | 716/1000 [00:07<00:02, 125.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 701/1000] Total Loss: 416.417114, Reconstruction Loss: 0.001357, Batch size: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  82%|████████▏ | 820/1000 [00:07<00:01, 125.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 801/1000] Total Loss: 415.982834, Reconstruction Loss: 0.001365, Batch size: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  92%|█████████▏| 924/1000 [00:08<00:00, 125.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 901/1000] Total Loss: 415.808937, Reconstruction Loss: 0.001362, Batch size: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 1000/1000 [00:09<00:00, 107.66it/s]\n",
      "/home/bernaljp/packages/scHopfield/scHopfield/inference/optimizer.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mask', torch.tensor(mask, dtype=torch.float32, device=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1000/1000] Total Loss: 415.750565, Reconstruction Loss: 0.001363, Batch size: 39\n",
      "Inferring interaction matrix W and bias vector I for cluster Meg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   3%|▎         | 26/1000 [00:00<00:03, 250.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Total Loss: 1423.506836, Reconstruction Loss: 17.934033, Batch size: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█▎        | 133/1000 [00:00<00:03, 258.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 101/1000] Total Loss: 631.522369, Reconstruction Loss: 0.122678, Batch size: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  24%|██▍       | 239/1000 [00:00<00:02, 262.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 201/1000] Total Loss: 500.799606, Reconstruction Loss: 0.019913, Batch size: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  35%|███▍      | 348/1000 [00:01<00:02, 266.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 301/1000] Total Loss: 449.427032, Reconstruction Loss: 0.008338, Batch size: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  43%|████▎     | 429/1000 [00:01<00:02, 265.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 401/1000] Total Loss: 429.233444, Reconstruction Loss: 0.006842, Batch size: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  54%|█████▎    | 537/1000 [00:02<00:01, 260.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 501/1000] Total Loss: 421.135483, Reconstruction Loss: 0.006548, Batch size: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  64%|██████▍   | 645/1000 [00:02<00:01, 261.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 601/1000] Total Loss: 417.851517, Reconstruction Loss: 0.006721, Batch size: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  75%|███████▌  | 753/1000 [00:02<00:00, 261.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 701/1000] Total Loss: 416.560883, Reconstruction Loss: 0.006754, Batch size: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  83%|████████▎ | 834/1000 [00:03<00:00, 261.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 801/1000] Total Loss: 416.044662, Reconstruction Loss: 0.006795, Batch size: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  94%|█████████▍| 942/1000 [00:03<00:00, 261.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 901/1000] Total Loss: 415.836624, Reconstruction Loss: 0.006626, Batch size: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 1000/1000 [00:03<00:00, 262.06it/s]\n",
      "/home/bernaljp/packages/scHopfield/scHopfield/inference/optimizer.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mask', torch.tensor(mask, dtype=torch.float32, device=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1000/1000] Total Loss: 415.756989, Reconstruction Loss: 0.006736, Batch size: 26\n",
      "Inferring interaction matrix W and bias vector I for cluster MEP-like\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   1%|          | 12/1000 [00:00<00:08, 116.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Total Loss: 1503.864365, Reconstruction Loss: 5.454681, Batch size: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 116/1000 [00:00<00:07, 121.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 101/1000] Total Loss: 594.605682, Reconstruction Loss: 0.044938, Batch size: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  22%|██▏       | 220/1000 [00:01<00:06, 121.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 201/1000] Total Loss: 483.699150, Reconstruction Loss: 0.009513, Batch size: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  32%|███▏      | 324/1000 [00:02<00:05, 121.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 301/1000] Total Loss: 443.564026, Reconstruction Loss: 0.001889, Batch size: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  42%|████▏     | 415/1000 [00:03<00:04, 121.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 401/1000] Total Loss: 426.964180, Reconstruction Loss: 0.000926, Batch size: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  52%|█████▏    | 519/1000 [00:04<00:03, 121.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 501/1000] Total Loss: 420.224289, Reconstruction Loss: 0.000853, Batch size: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  62%|██████▏   | 623/1000 [00:05<00:03, 121.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 601/1000] Total Loss: 417.510101, Reconstruction Loss: 0.000853, Batch size: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  71%|███████▏  | 714/1000 [00:05<00:02, 120.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 701/1000] Total Loss: 416.421082, Reconstruction Loss: 0.000862, Batch size: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  82%|████████▏ | 818/1000 [00:06<00:01, 121.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 801/1000] Total Loss: 415.983902, Reconstruction Loss: 0.000881, Batch size: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  92%|█████████▏| 922/1000 [00:07<00:00, 121.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 901/1000] Total Loss: 415.809464, Reconstruction Loss: 0.000869, Batch size: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 1000/1000 [00:08<00:00, 121.29it/s]\n",
      "/home/bernaljp/packages/scHopfield/scHopfield/inference/optimizer.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mask', torch.tensor(mask, dtype=torch.float32, device=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1000/1000] Total Loss: 415.750427, Reconstruction Loss: 0.000884, Batch size: 73\n",
      "Inferring interaction matrix W and bias vector I for cluster Ery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   2%|▏         | 23/1000 [00:00<00:04, 229.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Total Loss: 1419.302643, Reconstruction Loss: 13.597199, Batch size: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  14%|█▍        | 143/1000 [00:00<00:03, 236.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 101/1000] Total Loss: 626.569519, Reconstruction Loss: 0.099611, Batch size: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  24%|██▍       | 239/1000 [00:01<00:03, 236.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 201/1000] Total Loss: 499.957260, Reconstruction Loss: 0.016522, Batch size: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  34%|███▎      | 335/1000 [00:01<00:02, 236.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 301/1000] Total Loss: 449.353897, Reconstruction Loss: 0.003710, Batch size: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  43%|████▎     | 431/1000 [00:01<00:02, 235.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 401/1000] Total Loss: 429.217529, Reconstruction Loss: 0.002286, Batch size: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  53%|█████▎    | 527/1000 [00:02<00:02, 235.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 501/1000] Total Loss: 421.097702, Reconstruction Loss: 0.002105, Batch size: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  65%|██████▍   | 647/1000 [00:02<00:01, 236.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 601/1000] Total Loss: 417.850037, Reconstruction Loss: 0.002082, Batch size: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  74%|███████▍  | 743/1000 [00:03<00:01, 235.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 701/1000] Total Loss: 416.557449, Reconstruction Loss: 0.002081, Batch size: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  84%|████████▍ | 839/1000 [00:03<00:00, 236.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 801/1000] Total Loss: 416.039703, Reconstruction Loss: 0.002086, Batch size: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  94%|█████████▎| 935/1000 [00:03<00:00, 236.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 901/1000] Total Loss: 415.832687, Reconstruction Loss: 0.002090, Batch size: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 1000/1000 [00:04<00:00, 235.98it/s]\n",
      "/home/bernaljp/packages/scHopfield/scHopfield/inference/optimizer.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mask', torch.tensor(mask, dtype=torch.float32, device=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1000/1000] Total Loss: 415.752579, Reconstruction Loss: 0.002090, Batch size: 106\n",
      "Inferring interaction matrix W and bias vector I for cluster Bas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   2%|▏         | 24/1000 [00:00<00:04, 237.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Total Loss: 1421.588928, Reconstruction Loss: 15.623435, Batch size: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█▎        | 127/1000 [00:00<00:03, 250.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 101/1000] Total Loss: 630.233246, Reconstruction Loss: 0.120083, Batch size: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  23%|██▎       | 231/1000 [00:00<00:03, 251.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 201/1000] Total Loss: 500.113358, Reconstruction Loss: 0.018184, Batch size: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  33%|███▎      | 334/1000 [00:01<00:02, 250.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 301/1000] Total Loss: 449.335922, Reconstruction Loss: 0.004589, Batch size: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  44%|████▍     | 438/1000 [00:01<00:02, 251.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 401/1000] Total Loss: 429.221344, Reconstruction Loss: 0.003009, Batch size: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  54%|█████▍    | 542/1000 [00:02<00:01, 250.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 501/1000] Total Loss: 421.110138, Reconstruction Loss: 0.002666, Batch size: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  65%|██████▍   | 646/1000 [00:02<00:01, 250.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 601/1000] Total Loss: 417.852737, Reconstruction Loss: 0.002579, Batch size: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  75%|███████▌  | 750/1000 [00:02<00:00, 251.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 701/1000] Total Loss: 416.556580, Reconstruction Loss: 0.002653, Batch size: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  83%|████████▎ | 828/1000 [00:03<00:00, 251.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 801/1000] Total Loss: 416.040482, Reconstruction Loss: 0.002590, Batch size: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  93%|█████████▎| 932/1000 [00:03<00:00, 251.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 901/1000] Total Loss: 415.833099, Reconstruction Loss: 0.002727, Batch size: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 1000/1000 [00:03<00:00, 250.60it/s]\n",
      "/home/bernaljp/packages/scHopfield/scHopfield/inference/optimizer.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mask', torch.tensor(mask, dtype=torch.float32, device=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1000/1000] Total Loss: 415.753098, Reconstruction Loss: 0.002780, Batch size: 49\n",
      "Inferring interaction matrix W and bias vector I for cluster GMP-like\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   3%|▎         | 28/1000 [00:00<00:08, 117.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Total Loss: 1412.804810, Reconstruction Loss: 7.150844, Batch size: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  14%|█▎        | 136/1000 [00:00<00:03, 237.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 101/1000] Total Loss: 626.990173, Reconstruction Loss: 0.078865, Batch size: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  24%|██▍       | 244/1000 [00:01<00:02, 257.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 201/1000] Total Loss: 500.154099, Reconstruction Loss: 0.008633, Batch size: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  35%|███▌      | 352/1000 [00:01<00:02, 261.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 301/1000] Total Loss: 449.606689, Reconstruction Loss: 0.001616, Batch size: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  43%|████▎     | 433/1000 [00:01<00:02, 262.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 401/1000] Total Loss: 429.287613, Reconstruction Loss: 0.000765, Batch size: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  54%|█████▍    | 541/1000 [00:02<00:01, 260.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 501/1000] Total Loss: 421.138992, Reconstruction Loss: 0.000638, Batch size: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  65%|██████▍   | 649/1000 [00:02<00:01, 259.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 601/1000] Total Loss: 417.865723, Reconstruction Loss: 0.000625, Batch size: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  73%|███████▎  | 727/1000 [00:02<00:01, 258.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 701/1000] Total Loss: 416.563873, Reconstruction Loss: 0.000613, Batch size: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  83%|████████▎ | 832/1000 [00:03<00:00, 258.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 801/1000] Total Loss: 416.042328, Reconstruction Loss: 0.000648, Batch size: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  94%|█████████▎| 936/1000 [00:03<00:00, 258.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 901/1000] Total Loss: 415.832474, Reconstruction Loss: 0.000627, Batch size: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 1000/1000 [00:04<00:00, 248.69it/s]\n",
      "/home/bernaljp/packages/scHopfield/scHopfield/inference/optimizer.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mask', torch.tensor(mask, dtype=torch.float32, device=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1000/1000] Total Loss: 415.751541, Reconstruction Loss: 0.000626, Batch size: 33\n",
      "Inferring interaction matrix W and bias vector I for cluster HSC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   2%|▏         | 16/1000 [00:00<00:06, 159.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Total Loss: 1601.932495, Reconstruction Loss: 4.422511, Batch size: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|█▏        | 118/1000 [00:00<00:05, 163.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 101/1000] Total Loss: 605.674744, Reconstruction Loss: 0.061502, Batch size: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  22%|██▏       | 220/1000 [00:01<00:04, 163.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 201/1000] Total Loss: 493.738302, Reconstruction Loss: 0.009333, Batch size: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  32%|███▏      | 322/1000 [00:01<00:04, 162.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 301/1000] Total Loss: 447.410136, Reconstruction Loss: 0.002350, Batch size: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  42%|████▏     | 424/1000 [00:02<00:03, 163.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 401/1000] Total Loss: 428.401286, Reconstruction Loss: 0.000840, Batch size: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  53%|█████▎    | 526/1000 [00:03<00:02, 164.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 501/1000] Total Loss: 420.768066, Reconstruction Loss: 0.000633, Batch size: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  63%|██████▎   | 628/1000 [00:03<00:02, 164.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 601/1000] Total Loss: 417.719991, Reconstruction Loss: 0.000641, Batch size: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  73%|███████▎  | 730/1000 [00:04<00:01, 164.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 701/1000] Total Loss: 416.502981, Reconstruction Loss: 0.000659, Batch size: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  83%|████████▎ | 832/1000 [00:05<00:01, 164.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 801/1000] Total Loss: 416.015381, Reconstruction Loss: 0.000643, Batch size: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  93%|█████████▎| 934/1000 [00:05<00:00, 164.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 901/1000] Total Loss: 415.821777, Reconstruction Loss: 0.000638, Batch size: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 1000/1000 [00:06<00:00, 163.95it/s]\n",
      "/home/bernaljp/packages/scHopfield/scHopfield/inference/optimizer.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mask', torch.tensor(mask, dtype=torch.float32, device=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1000/1000] Total Loss: 415.749095, Reconstruction Loss: 0.000654, Batch size: 53\n",
      "Inferring interaction matrix W and bias vector I for cluster Neu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   6%|▌         | 57/1000 [00:00<00:01, 568.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Total Loss: 723.864197, Reconstruction Loss: 0.435890, Batch size: 32\n",
      "[Epoch 101/1000] Total Loss: 637.088867, Reconstruction Loss: 0.408541, Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  29%|██▉       | 294/1000 [00:00<00:01, 585.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 201/1000] Total Loss: 507.032715, Reconstruction Loss: 0.039207, Batch size: 32\n",
      "[Epoch 301/1000] Total Loss: 451.542542, Reconstruction Loss: 0.008933, Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  47%|████▋     | 471/1000 [00:00<00:00, 584.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 401/1000] Total Loss: 430.517395, Reconstruction Loss: 0.005151, Batch size: 32\n",
      "[Epoch 501/1000] Total Loss: 421.665771, Reconstruction Loss: 0.004800, Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  71%|███████   | 708/1000 [00:01<00:00, 586.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 601/1000] Total Loss: 418.061859, Reconstruction Loss: 0.004845, Batch size: 32\n",
      "[Epoch 701/1000] Total Loss: 416.649139, Reconstruction Loss: 0.004841, Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  89%|████████▊ | 887/1000 [00:01<00:00, 587.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 801/1000] Total Loss: 416.078033, Reconstruction Loss: 0.004857, Batch size: 32\n",
      "[Epoch 901/1000] Total Loss: 415.849640, Reconstruction Loss: 0.004863, Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 1000/1000 [00:01<00:00, 584.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1000/1000] Total Loss: 415.757507, Reconstruction Loss: 0.004865, Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "sch.inf.fit_interactions(adata,\n",
    "                         cluster_key=CLUSTER_KEY,\n",
    "                         spliced_key=SPLICED_KEY,\n",
    "                         velocity_key=VELOCITY_KEY,\n",
    "                         degradation_key=DEGRADATION_KEY,\n",
    "                         w_threshold=1e-12,\n",
    "                         w_scaffold=scaffold.values,\n",
    "                         scaffold_regularization=1e-2,\n",
    "                         only_TFs=True,\n",
    "                         infer_I=True,\n",
    "                         refit_gamma=False,\n",
    "                         pre_initialize_W=False,\n",
    "                         n_epochs=1000,\n",
    "                         criterion='MSE',\n",
    "                         batch_size=128,\n",
    "                         skip_all=True,\n",
    "                         use_scheduler=True,\n",
    "                         get_plots=False,\n",
    "                         device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_energies() got an unexpected keyword argument 'cluster_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Compute energies using scHopfield\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_energies\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCLUSTER_KEY\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: compute_energies() got an unexpected keyword argument 'cluster_key'"
     ]
    }
   ],
   "source": [
    "# Compute energies using scHopfield\n",
    "sch.tl.compute_energies(adata, cluster_key=CLUSTER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = ls.adata.obs[[cluster_key,'Total_energy','Interaction_energy','Degradation_energy','Bias_energy']].groupby(cluster_key).describe()\n",
    "for energy in summary_stats.columns.levels[0]:\n",
    "    summary_stats[(energy,'cv')] = summary_stats[(energy,'std')]/summary_stats[(energy,'mean')]\n",
    "# summary_stats.to_csv('/home/bernaljp/KAUST/summary_stats_hematopoiesis.csv')\n",
    "summary_stats['Total_energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[colors[i] for i in order])\n",
    "ls.plot_energy_boxplots(figsize=(22,11), order=order, colors=colors)\n",
    "ls.plot_energy_scatters(figsize=(15,15), order=order)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(-0.2, 1.2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dendrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell type dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.celltype_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3))\n",
    "Z = scp.cluster.hierarchy.linkage(squareform(1-ls.cells_correlation), 'complete', )\n",
    "fig,axs = plt.subplots(1,1,figsize=(10, 4), tight_layout=True)\n",
    "scp.cluster.hierarchy.dendrogram(Z, labels = ls.cells_correlation.index, ax=axs)\n",
    "axs.get_yaxis().set_visible(False)\n",
    "axs.spines['top'].set_visible(False)\n",
    "axs.spines['right'].set_visible(False)\n",
    "axs.spines['bottom'].set_visible(False)\n",
    "axs.spines['left'].set_visible(False)\n",
    "axs.set_title('Celltype RV score')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.network_correlations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,1,figsize=(9, 3), tight_layout=True)\n",
    "axs.get_yaxis().set_visible(False)\n",
    "axs.spines['top'].set_visible(False)\n",
    "axs.spines['right'].set_visible(False)\n",
    "axs.spines['bottom'].set_visible(False)\n",
    "axs.spines['left'].set_visible(False)\n",
    "\n",
    "Z = scp.cluster.hierarchy.linkage(squareform(1-ls.pearson), 'complete', )\n",
    "scp.cluster.hierarchy.dendrogram(Z, labels = ls.pearson.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,1,figsize=(10, 4), tight_layout=True)\n",
    "axs.get_yaxis().set_visible(False)\n",
    "axs.spines['top'].set_visible(False)\n",
    "axs.spines['right'].set_visible(False)\n",
    "axs.spines['bottom'].set_visible(False)\n",
    "axs.spines['left'].set_visible(False)\n",
    "axs.set_title('Network Hamming Distance Dendrogram')\n",
    "\n",
    "Z = scp.cluster.hierarchy.linkage(squareform(ls.hamming), 'complete', )\n",
    "scp.cluster.hierarchy.dendrogram(Z, labels = ls.hamming.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,1,figsize=(10, 3), tight_layout=True)\n",
    "axs.get_yaxis().set_visible(False)\n",
    "axs.spines['top'].set_visible(False)\n",
    "axs.spines['right'].set_visible(False)\n",
    "axs.spines['bottom'].set_visible(False)\n",
    "axs.spines['left'].set_visible(False)\n",
    "\n",
    "Z = scp.cluster.hierarchy.linkage(squareform(1-ls.pearson_bin), 'complete', )\n",
    "scp.cluster.hierarchy.dendrogram(Z, labels = ls.pearson_bin.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symmetricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetricity(A, norm=2):\n",
    "    S = np.linalg.norm((A+A.T)/2, ord=norm)\n",
    "    As = np.linalg.norm((A-A.T)/2, ord=norm )\n",
    "    return (S-As)/(S+As)\n",
    "\n",
    "syms = np.array([symmetricity(ls.W[k], norm=2) for k in order])\n",
    "idxs = np.argsort(syms)\n",
    "plt.figure(figsize=(5,4), tight_layout=True)\n",
    "# plt.plot(syms[idxs], '.')\n",
    "# plt.xticks(range(len(ls.W)-1), np.array(order)[idxs])\n",
    "# plt.plot(syms, '*')\n",
    "plt.scatter(range(len(ls.W)), syms, s=200, marker='*', c=[colors[i] for i in order])\n",
    "plt.xticks(range(len(ls.W)), np.array(order))\n",
    "plt.ylabel('Symmetricity')\n",
    "plt.xticks(rotation=-30)\n",
    "\n",
    "\n",
    "plt.title('Distribution of Symmetricity across Weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,4,figsize=(20,10))\n",
    "for cl,ax in zip(order,axs.flatten()):\n",
    "    ax.scatter(ls.gamma[cl], ls.adata.var[ls.gamma_key][ls.genes], color=colors[cl], s=2)\n",
    "    ax.set_title(cl)\n",
    "    max_gamma = max(np.concatenate([ls.gamma[cl], ls.adata.var[ls.gamma_key][ls.genes]]))\n",
    "    ax.set_xlabel('Refitted gamma')\n",
    "    ax.set_ylabel('Original gamma')\n",
    "    ax.plot([0, max_gamma], [0, max_gamma], color='k', ls='--', lw=1)\n",
    "    # ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,4,figsize=(20,10))\n",
    "for cl,ax in zip(order,axs.flatten()):\n",
    "   sns.histplot(ls.I[cl].flatten(), bins=100,ax=ax, color=colors[cl])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,4,figsize=(20,10))\n",
    "for cl,ax in zip(order,axs.flatten()):\n",
    "    reconstructed_v = ls.hopfield_model(cl)\n",
    "    original_v = ls.adata.layers[ls.velocity_key][ls.adata.obs[ls.cluster_key]==cl][:,ls.genes]\n",
    "    mse = np.mean((reconstructed_v-original_v.A)**2)\n",
    "    ax.scatter(reconstructed_v.flatten(), original_v.A.flatten(), color=colors[cl], s=2)\n",
    "    ax.set_title(f'{cl} - MSE: {mse:.2f}')\n",
    "    ax.set_xlabel('Reconstructed velocity')\n",
    "    ax.set_ylabel('Original velocity')\n",
    "    min_v = min(np.concatenate([reconstructed_v.flatten(), original_v.A.flatten()]))\n",
    "    max_v = max(np.concatenate([reconstructed_v.flatten(), original_v.A.flatten()]))\n",
    "    ax.plot([min_v, max_v], [min_v, max_v], c='k', ls='--', lw=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_table(ls, n_top_genes=20, which_correlation='total'):\n",
    "    corr = 'correlation_'+which_correlation.lower() if which_correlation.lower()!='total' else 'correlation'\n",
    "    assert hasattr(ls, corr), f'No {corr} attribute found in Landscape object'\n",
    "    corrs_dict = getattr(ls,corr)\n",
    "    df = pd.DataFrame(index=range(n_top_genes), columns=pd.MultiIndex.from_product([order, ['Gene', 'Correlation']]))\n",
    "    for k in order:\n",
    "        corrs = corrs_dict[k]\n",
    "        indices = np.argsort(corrs)[::-1][:n_top_genes]\n",
    "        genes = ls.gene_names[indices]\n",
    "        corrs = corrs[indices]\n",
    "        df[(k, 'Gene')] = genes\n",
    "        df[(k, 'Correlation')] = corrs\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correlations = get_correlation_table(ls, n_top_genes=100, which_correlation='total')\n",
    "df_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_genes = np.array([])\n",
    "clus1_low = -0.4\n",
    "clus1_high = 0.4\n",
    "clus2_low = -0.4\n",
    "clus2_high = 0.4\n",
    "nn = 5\n",
    " \n",
    "for corr1,corr2 in itertools.combinations(order, 2):\n",
    "    corr1 = ls.correlation[corr1]\n",
    "    corr2 = ls.correlation[corr2]\n",
    "    positions_corners = np.logical_or(np.logical_and(corr1 >= clus1_high, corr2 <= clus2_low), np.logical_and(corr1 <= clus1_low, corr2 >= clus2_high))\n",
    "\n",
    "    # Identify correlations that are in opposite corners of the plot\n",
    "    corr_corners = np.where(positions_corners)[0]\n",
    "    corr_indices = np.argsort((corr1[corr_corners])**2 + (corr2[corr_corners])**2)[-nn:]\n",
    "    corr_corners = corr_corners[corr_indices]\n",
    "    corner_genes = np.concatenate((corner_genes, ls.gene_names[corr_corners]))\n",
    "\n",
    "corner_genes = np.unique(corner_genes)\n",
    "df_corr_corners = pd.DataFrame.from_dict(ls.correlation)\n",
    "df_corr_corners.drop('all', axis=1, inplace=True)\n",
    "df_corr_corners.index = ls.gene_names\n",
    "df_corr_corners = df_corr_corners.loc[corner_genes]\n",
    "df_corr_corners.to_csv(f'/home/bernaljp/KAUST/corner_genes_{name}.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.plot_correlations_grid(energy='total', order=order, colors=colors, x_low=-0.4, y_high=0.4, x_high=0.4, y_low=-0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.plot_correlations_grid(energy='interaction', order=order, colors=colors, x_low=-0.4, y_high=0.4, x_high=0.4, y_low=-0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(18,6),tight_layout=True)\n",
    "if name.lower() in ['endocrinogenesis', 'endocrinogenesis_preprocessed']:\n",
    "    ls.plot_gene_correlation_scatter('Ngn3 high EP', 'Pre-endocrine', energy='total', annotate=6, ax=ax[0])\n",
    "    ls.plot_gene_correlation_scatter('Alpha', 'Delta', energy='total', annotate=6, ax=ax[1])\n",
    "    ls.plot_gene_correlation_scatter('Ngn3 high EP', 'Pre-endocrine', energy='total', annotate=6, ax=ax[2])\n",
    "else:\n",
    "    ls.plot_gene_correlation_scatter('Meg', 'Ery', energy='total', annotate=6, ax=ax[0], clus1_low=-0.4, clus1_high=0.4, clus2_low=-0.4, clus2_high=0.4)\n",
    "    ls.plot_gene_correlation_scatter('Neu', 'Bas', energy='total', annotate=6, ax=ax[1])\n",
    "    ls.plot_gene_correlation_scatter('Neu', 'Mon', energy='total', annotate=6, ax=ax[2])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_dict(ls):\n",
    "    links = {}\n",
    "    for k, w in ls.W.items():\n",
    "        links[k] = pd.DataFrame(w.T, index=ls.gene_names, columns=ls.gene_names).reset_index()\n",
    "        links[k] = links[k].melt(id_vars='index', value_vars=links[k].columns, var_name='target', value_name='coef_mean')\n",
    "        links[k] = links[k][links[k]['coef_mean'] != 0]\n",
    "        links[k].rename(columns={'index': 'source'}, inplace=True)\n",
    "        links[k]['coef_abs'] = np.abs(links[k]['coef_mean'])\n",
    "        links[k]['p'] = 0\n",
    "        links[k]['-logp'] = np.nan\n",
    "    return links\n",
    "\n",
    "def plot_scores_as_rank(links, clusters=None, axs=None, n_gene=50, values=None, colors=None, skip_first_n=0, return_table=False):\n",
    "    \"\"\"\n",
    "    Pick up top n-th genes wich high-network scores and make plots.\n",
    "\n",
    "    Args:\n",
    "        links (Links object): See network_analisis.Links class for detail.\n",
    "        cluster (str): Cluster nome to analyze.\n",
    "        n_gene (int): Number of genes to plot. Default is 50.\n",
    "        save (str): Folder path to save plots. If the folde does not exist in the path, the function create the folder.\n",
    "            If None plots will not be saved. Default is None.\n",
    "    \"\"\"\n",
    "    values = links.merged_score.columns.drop('cluster') if values is None else values\n",
    "    n_cols = len(values)\n",
    "    clusters = links.cluster if clusters is None else np.array([clusters]).ravel().tolist()\n",
    "    n_rows = len(clusters)\n",
    "    size_per_gene = 0.2\n",
    "\n",
    "    _, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*n_gene*size_per_gene), tight_layout=True) if axs is None else (None,axs)\n",
    "\n",
    "    df_table = pd.DataFrame(index=range(n_gene), columns=pd.MultiIndex.from_product([clusters, values, ['Gene','Value']], names=['cluster', 'score', 'values']))\n",
    "    \n",
    "    for i, (axs_row, cluster) in enumerate(zip(axs, clusters)):\n",
    "        color = colors[cluster] if colors is not None else 'tab:blue'\n",
    "        for j, (ax, value) in enumerate(zip(axs_row, values)):\n",
    "            res = links.merged_score[links.merged_score.cluster == cluster]\n",
    "            res = res[value].sort_values(ascending=False)\n",
    "            res = res[skip_first_n:n_gene+skip_first_n]\n",
    "\n",
    "            ax.scatter(res.values, range(len(res)), color=color)\n",
    "            ax.set_yticks(range(len(res)), res.index.values)\n",
    "            if i == 0:\n",
    "                if skip_first_n == 0:\n",
    "                    ax.set_title(f\" {value.replace('_',' ').capitalize()} \\n top {n_gene}\")\n",
    "                else:\n",
    "                    ax.set_title(f\" {value.replace('_',' ').capitalize()} \\n top {n_gene} (skip {skip_first_n})\")\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(cluster)            \n",
    "            ax.invert_yaxis()\n",
    "\n",
    "            if return_table:\n",
    "                df_table[(cluster, value, 'Gene')] = res.index.values\n",
    "                df_table[(cluster, value, 'Value')] = res.values\n",
    "    if return_table:\n",
    "        return df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_goi(x, y, goi, args_annot, scatter=False, x_shift=0.1, y_shift=0.1, ax=None):\n",
    "    \"\"\"\n",
    "    Plot an annoation to highlight one point in scatter plot.\n",
    "\n",
    "    Args:\n",
    "        x (float): Cordinate-x.\n",
    "        y (float): Cordinate-y.\n",
    "        args_annot (dictionary): arguments for matplotlib.pyplot.annotate().\n",
    "        scatter (bool): Whether to plot dot for the point of interest.\n",
    "        x_shift (float): distance between the annotation and the point of interest in the x-axis.\n",
    "        y_shift (float): distance between the annotation and the point of interest in the y-axis.\n",
    "    \"\"\"\n",
    "\n",
    "    default = {\"size\": 10}\n",
    "    default.update(args_annot)\n",
    "    args_annot = default.copy()\n",
    "\n",
    "    arrow_dict = {\"width\": 0.5, \"headwidth\": 0.5, \"headlength\": 1, \"color\": \"black\"}\n",
    "    plotter = plt if ax is None else ax\n",
    "    if scatter:\n",
    "        plotter.scatter(x, y, c=\"none\", edgecolor=\"black\")\n",
    "    plotter.annotate(f\"{goi}\", xy=(x, y), xytext=(x+x_shift, y+y_shift),\n",
    "                 color=\"black\", arrowprops=arrow_dict, **args_annot)\n",
    "    \n",
    "def plot_score_comparison_2D(links, value, cluster1, cluster2, percentile=99, annot_shifts=None, save=None, fillna_with_zero=True, ignore_genes=[], plt_show=True, ax=None):\n",
    "    \"\"\"\n",
    "    Make a scatter plot that shows the relationship of a specific network score in two groups.\n",
    "\n",
    "    Args:\n",
    "        links (Links object): See network_analisis.Links class for detail.\n",
    "        value (srt): The network score to be shown.\n",
    "        cluster1 (str): Cluster nome to analyze. Network scores in the cluste1 are shown as x-axis.\n",
    "        cluster2 (str): Cluster nome to analyze. Network scores in the cluste2 are shown as y-axis.\n",
    "        percentile (float): Genes with a network score above the percentile will be shown with annotation. Default is 99.\n",
    "        annot_shifts ((float, float)): Shift x and y cordinate for annotations.\n",
    "        save (str): Folder path to save plots. If the folde does not exist in the path, the function create the folder.\n",
    "            If None plots will not be saved. Default is None.\n",
    "    \"\"\"\n",
    "    res = links.merged_score[links.merged_score.cluster.isin([cluster1, cluster2])][[value, \"cluster\"]]\n",
    "    res = res.reset_index(drop=False)\n",
    "    piv = pd.pivot_table(res, values=value, columns=\"cluster\", index=\"index\")\n",
    "    piv.drop(ignore_genes, inplace=True, errors='ignore')\n",
    "    if fillna_with_zero:\n",
    "        piv = piv.fillna(0)\n",
    "    else:\n",
    "        piv = piv.fillna(piv.mean(axis=0))\n",
    "\n",
    "    goi1 = piv[piv[cluster1] > np.percentile(piv[cluster1].values, percentile)].index\n",
    "    goi2 = piv[piv[cluster2] > np.percentile(piv[cluster2].values, percentile)].index\n",
    "\n",
    "    gois = np.union1d(goi1, goi2)\n",
    "    not_gois = np.setdiff1d(piv.index, gois)\n",
    "    piv_gois = piv.loc[gois]\n",
    "    piv_not_gois = piv.loc[not_gois]\n",
    "\n",
    "    x, y = piv_not_gois[cluster1], piv_not_gois[cluster2]\n",
    "    plotter = plt if ax is None else ax\n",
    "    plotter.scatter(x, y, c='lightgray', s=2)\n",
    "    x, y = piv_gois[cluster1], piv_gois[cluster2]\n",
    "    plotter.scatter(x, y, c=\"none\", edgecolors='b')\n",
    "\n",
    "    if annot_shifts is None:\n",
    "        x_shift, y_shift = (x.max() - x.min())*0.03, (y.max() - y.min())*0.03\n",
    "    else:\n",
    "        x_shift, y_shift = annot_shifts\n",
    "    for goi in gois:\n",
    "        x, y = piv.loc[goi, cluster1], piv.loc[goi, cluster2]\n",
    "        _plot_goi(x, y, goi, {}, scatter=False, x_shift=x_shift, y_shift=y_shift, ax=ax)\n",
    "\n",
    "    if ax is None:\n",
    "        plt.xlabel(cluster1)\n",
    "        plt.ylabel(cluster2)\n",
    "        # plt.title(f\"{value}\")\n",
    "    else:\n",
    "        ax.set_xlabel(cluster1)\n",
    "        ax.set_ylabel(cluster2)\n",
    "\n",
    "\n",
    "    if not save is None:\n",
    "        os.makedirs(save, exist_ok=True)\n",
    "        path = os.path.join(save, f\"values_comparison_in_{links.name}_{value}_{links.threshold_number}_{cluster1}_vs_{cluster2}.{settings['save_figure_as']}\")\n",
    "        plt.savefig(path, transparent=True)\n",
    "    if plt_show:\n",
    "        plt.show()\n",
    "def plot_score_per_cluster(links, goi, save=None, plt_show=True, ax=None):\n",
    "    \"\"\"\n",
    "    Plot network score for a specific gene.\n",
    "    This function can be used to compare network score of a specific gene between clusters\n",
    "    and get insight about the dynamics of the gene.\n",
    "\n",
    "    Args:\n",
    "        links (Links object): See network_analisis.Links class for detail.\n",
    "        goi (srt): Gene name.\n",
    "        save (str): Folder path to save plots. If the folde does not exist in the path, the function create the folder.\n",
    "            If None plots will not be saved. Default is None.\n",
    "    \"\"\"\n",
    "    print(goi)\n",
    "    res = links.merged_score[links.merged_score.index==goi]\n",
    "    res = res.rename(\n",
    "        columns={\"degree_centrality_all\": \"degree\\ncentrality\",\n",
    "                 \"betweenness_centrality\": \"betweenness\\ncentrality\",\n",
    "                 \"eigenvector_centrality\": \"eigenvector\\ncentrality\"})\n",
    "    # make plots\n",
    "    values = [ \"degree\\ncentrality\",  \"betweenness\\ncentrality\",\n",
    "              \"eigenvector\\ncentrality\"]\n",
    "    for i, value in zip([1, 2, 3], values):\n",
    "        plt.subplot(1, 3,  i)\n",
    "        ax = sns.stripplot(data=res, y=\"cluster\", x=value,\n",
    "                      size=10, orient=\"h\",linewidth=1, edgecolor=\"w\",\n",
    "                      order=links.palette.index.values,\n",
    "                      palette=dict(links.palette.palette))\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.yaxis.grid(True)\n",
    "        ax.tick_params(bottom=False,\n",
    "                        left=False,\n",
    "                        right=False,\n",
    "                        top=False)\n",
    "        if i > 1:\n",
    "            plt.ylabel(None)\n",
    "            ax.tick_params(labelleft=False)\n",
    "\n",
    "    if not save is None:\n",
    "        os.makedirs(save, exist_ok=True)\n",
    "        path = os.path.join(save,\n",
    "                           f\"score_dynamics_in_{links.name}_{links.threshold_number}_{goi}.{settings['save_figure_as']}\")\n",
    "        plt.savefig(path, transparent=True)\n",
    "    if plt_show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_comparison_grid(links, score=\"eigenvector_centrality\", colors=None, order=None, ignore_genes=[], annotate_percentile=99, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots a matrix where the diagonal shows cell types and the off-diagonal\n",
    "    plots show gene correlation scatter plots between cell types.\n",
    "\n",
    "    Args:\n",
    "        cell_types (list): List of cell types to plot.\n",
    "        colors (dict): Dictionary mapping cell types to colors.\n",
    "        name (str): Name of the plot or dataset for title adjustments.\n",
    "    \"\"\"\n",
    "    cell_types = links.cluster if order is None else order\n",
    "    n = len(cell_types)\n",
    "    figsize = kwargs.pop('figsize', (15, 15))\n",
    "    fontsize = kwargs.pop('fontsize', 30)\n",
    "    tight_layout = kwargs.get('tight_layout', True)\n",
    "    colors = colors if colors is not None else links.palette.to_dict()['palette']\n",
    "    fig, axs = plt.subplots(n, n, figsize=figsize, tight_layout=tight_layout)\n",
    "    fig.suptitle(score.replace('_', ' ').capitalize(), fontsize=fontsize)\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            if i == j:\n",
    "                text = cell_types[i]\n",
    "                for spine in axs[i, j].spines.values():\n",
    "                    spine.set_visible(True)\n",
    "                    spine.set_linewidth(2)\n",
    "                    spine.set_color(colors[text])\n",
    "                # Remove ticks\n",
    "                axs[i, j].set_xticks([])\n",
    "                axs[i, j].set_yticks([])\n",
    "                # Add text in the middle\n",
    "                axs[i, j].set_facecolor(colors[text])\n",
    "                text = text.replace(' ', '\\n', 1)\n",
    "                text = text.replace('-', '-\\n')\n",
    "                axs[i, j].text(0.5, 0.5, text, ha='center', va='center', fontsize=18, fontweight='bold', fontname='serif', transform=axs[i, j].transAxes)\n",
    "                \n",
    "                \n",
    "                continue\n",
    "            \n",
    "            axs[i, j].axis('off')\n",
    "            plot_score_comparison_2D(links, value=score,\n",
    "                               cluster1=cell_types[i], cluster2=cell_types[j], \n",
    "                               percentile=annotate_percentile, ax=axs[j, i], plt_show=False, ignore_genes=ignore_genes, **kwargs)\n",
    "           # Remove ticks\n",
    "           \n",
    "            axs[j, i].set_xlabel('')\n",
    "            axs[j, i].set_ylabel('')\n",
    "            # Adjust ticks for the first column and last row\n",
    "            if i != 0: \n",
    "                axs[j, i].set_yticks([])\n",
    "            if j != n - 1:\n",
    "                axs[j, i].set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_per_cluster(links, goi, order=None, plt_show=True):\n",
    "    \"\"\"\n",
    "    Plot network score for a specific gene.\n",
    "    This function can be used to compare network score of a specific gene between clusters\n",
    "    and get insight about the dynamics of the gene.\n",
    "\n",
    "    Args:\n",
    "        links (Links object): See network_analisis.Links class for detail.\n",
    "        goi (srt): Gene name.\n",
    "        save (str): Folder path to save plots. If the folde does not exist in the path, the function create the folder.\n",
    "            If None plots will not be saved. Default is None.\n",
    "    \"\"\"\n",
    "    print(goi)\n",
    "    res = links.merged_score[links.merged_score.index==goi]\n",
    "    res = res.rename(\n",
    "        columns={\"degree_centrality_all\": \"degree\\ncentrality\",\n",
    "                 \"betweenness_centrality\": \"betweenness\\ncentrality\",\n",
    "                 \"eigenvector_centrality\": \"eigenvector\\ncentrality\"})\n",
    "    # make plots\n",
    "    values = [ \"degree\\ncentrality\",  \"betweenness\\ncentrality\",\n",
    "              \"eigenvector\\ncentrality\"]\n",
    "    order = links.palette.index.values if order is None else order\n",
    "    for i, value in zip([1, 2, 3], values):\n",
    "        plt.subplot(1, 3,  i)\n",
    "        ax = sns.stripplot(data=res, y=\"cluster\", x=value,\n",
    "                      size=10, orient=\"h\",linewidth=1, edgecolor=\"w\",\n",
    "                      order=order,\n",
    "                      palette=dict(links.palette.palette))\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.yaxis.grid(True)\n",
    "        ax.tick_params(bottom=False,\n",
    "                        left=False,\n",
    "                        right=False,\n",
    "                        top=False)\n",
    "        if i > 1:\n",
    "            plt.ylabel(None)\n",
    "            ax.tick_params(labelleft=False)\n",
    "\n",
    "    if plt_show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_dict = get_links_dict(ls)\n",
    "try:\n",
    "    links_dict.__delitem__('all')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "links = co.network_analysis.links_object.Links(name=ls.cluster_key, links_dict=links_dict)\n",
    "\n",
    "co.trajectory.oracle_utility._check_color_information_and_create_if_not_found(adata, ls.cluster_key, 'umap')\n",
    "ls.adata.uns[f'{ls.cluster_key}_colors']\n",
    "pd.DataFrame.from_dict(ls.adata.uns[f'{ls.cluster_key}_colors'], orient='index', columns=['palette'])\n",
    "# pd.DataFrame(ls.adata.uns[f'{ls.cluster_key}_colors'], index=ls.adata.obs[ls.cluster_key].unique(), columns=['palette'])\n",
    "\n",
    "try:\n",
    "    links.palette = pd.DataFrame.from_dict(ls.adata.uns[f'{cluster_key}_colors'], orient='index', columns=['palette'])\n",
    "except:\n",
    "    links.palette = pd.DataFrame(ls.adata.uns[f'{cluster_key}_colors'], index=ls.adata.obs[ls.cluster_key].unique(), columns=['palette'])\n",
    "\n",
    "links.filter_links(p=0.001, weight=\"coef_abs\", threshold_number=40000)\n",
    "\n",
    "# Calculate network scores. \n",
    "links.get_network_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links.links_dict['HSC'].source.unique()),len(links.links_dict['HSC'].target.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [\n",
    "          'degree_centrality_out',\n",
    "          'betweenness_centrality',  \n",
    "          'eigenvector_centrality',\n",
    "          ]\n",
    "df_scores = plot_scores_as_rank(links, clusters=order, values=values, colors=colors, n_gene=20, skip_first_n=0, return_table=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by cluster and get top 10 genes per cluster\n",
    "top_genes_per_cluster = (\n",
    "    links.merged_score[['betweenness_centrality','cluster']].groupby(\"cluster\", group_keys=False)\n",
    "    .apply(lambda x: x.nlargest(20, \"betweenness_centrality\")).reset_index(drop=False)\n",
    ")\n",
    "formatted_result = pd.DataFrame(index=range(20),columns=pd.MultiIndex.from_product([order, ['Gene', 'Betweenness']]))\n",
    "for cluster in order:\n",
    "    formatted_result[cluster] = top_genes_per_cluster[top_genes_per_cluster.cluster == cluster][['index', 'betweenness_centrality']].values\n",
    "formatted_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by cluster and get top 10 genes per cluster\n",
    "top_genes_per_cluster = (\n",
    "    links.merged_score[['degree_centrality_out','cluster']].groupby(\"cluster\", group_keys=False)\n",
    "    .apply(lambda x: x.nlargest(20, \"degree_centrality_out\")).reset_index(drop=False)\n",
    ")\n",
    "formatted_result = pd.DataFrame(index=range(20),columns=pd.MultiIndex.from_product([order, ['Gene', 'Degree Centrality']]))\n",
    "for cluster in order:\n",
    "    formatted_result[cluster] = top_genes_per_cluster[top_genes_per_cluster.cluster == cluster][['index', 'degree_centrality_out']].values\n",
    "formatted_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_result[[(cl,'Gene') for cl in order]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.merged_score[['betweenness_centrality','cluster']].loc[np.unique(formatted_result.iloc[:,::2].values)].reset_index(drop=False).pivot_table(index='index', columns='cluster', values='betweenness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score_comparison_grid(links, score=\"betweenness_centrality\", figsize=(20, 20), ignore_genes=[], annotate_percentile=99.6, order=order)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if name.lower() in ['endocrinogenesis', 'endocrinogenesis_preprocessed']:\n",
    "    list_of_genes = ['Malat1', 'Ins2', 'Ptprn2', 'Ghr', 'Ccnd2','Dach1', 'Actb', 'Etv1', 'Pdx1', 'Isl1', 'Hhex']\n",
    "elif name.lower() in ['hematopoiesis']:\n",
    "    # list_of_genes = [\"GATA2\", \"PLEK\", \"RUNX1\", \"GATA1\", \"CEBPA\", \"SPI1\"]\n",
    "    list_of_genes = ['ID2', 'HOXA10', 'RORA', 'TAL1', 'CUX1', 'GATA2', 'STAT2', 'SPI1', 'FOXP1']\n",
    "\n",
    "for gg in list_of_genes:\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plot_score_per_cluster(links, gg, order=order, plt_show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness vs Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "goi_high_betweenness_low_degree = pd.Index([])\n",
    "top_n_genes_per_cluster = {}\n",
    "for cl, ax in zip(order, axs.flat):\n",
    "    df_tmp = links.merged_score[links.merged_score.cluster == cl]\n",
    "    \n",
    "    # Filter genes with degree lower than 0.5\n",
    "    filtered_df = df_tmp[df_tmp['degree_centrality_all'] < 0.5]\n",
    "    \n",
    "    # Select top 3 genes with highest betweenness centrality\n",
    "    top_genes = filtered_df.nlargest(3, 'betweenness_centrality')\n",
    "    goi_high_betweenness_low_degree = goi_high_betweenness_low_degree.union(top_genes.index)\n",
    "    top_n_genes_per_cluster[cl] = top_genes['betweenness_centrality'].to_dict()\n",
    "    \n",
    "    # Plot scatter\n",
    "    df_tmp.plot(kind='scatter', x='betweenness_centrality', y='degree_centrality_all', \n",
    "                ax=ax, color=colors[cl], s=10)\n",
    "    \n",
    "    # Annotate top genes\n",
    "    for gene, row in top_genes.iterrows():\n",
    "        ax.annotate(gene, (row['betweenness_centrality'], row['degree_centrality_all']),\n",
    "                    fontsize=10, ha='right', va='bottom', color='black')\n",
    "\n",
    "    ax.set_title(cl)\n",
    "    ax.set_xlabel('Betweenness')\n",
    "    ax.set_ylabel('Degree')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "goi_high_betweenness_low_degree = pd.Index([])\n",
    "top_n_genes_per_cluster = {}\n",
    "for cl, ax in zip(order, axs.flat):\n",
    "    df_tmp = links.merged_score[links.merged_score.cluster == cl]\n",
    "    \n",
    "    # Filter genes with degree lower than 0.5\n",
    "    filtered_df = df_tmp[df_tmp['betweenness_centrality'] < 1000]\n",
    "    \n",
    "    # Select top 3 genes with highest betweenness centrality\n",
    "    top_genes = filtered_df.nlargest(3, 'degree_centrality_all')\n",
    "    goi_high_betweenness_low_degree = goi_high_betweenness_low_degree.union(top_genes.index)\n",
    "    top_n_genes_per_cluster[cl] = top_genes['degree_centrality_all'].to_dict()\n",
    "    \n",
    "    # Plot scatter\n",
    "    df_tmp.plot(kind='scatter', x='betweenness_centrality', y='degree_centrality_all', \n",
    "                ax=ax, color=colors[cl], s=10)\n",
    "    \n",
    "    # Annotate top genes\n",
    "    for gene, row in top_genes.iterrows():\n",
    "        ax.annotate(gene, (row['betweenness_centrality'], row['degree_centrality_all']),\n",
    "                    fontsize=10, ha='right', va='bottom', color='black')\n",
    "\n",
    "    ax.set_title(cl)\n",
    "    ax.set_xlabel('Betweenness')\n",
    "    ax.set_ylabel('Degree')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AHRR', 'CUX1', 'E2F4', 'ERG', 'HIVEP1', 'HOXA10', 'ID2', 'KLF16',\n",
       "       'MBD2', 'MEF2D', 'MEIS1', 'MLX', 'MYCN', 'MYPOP', 'NRF1', 'RUNX1',\n",
       "       'STAT2', 'TCF3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goi_high_betweenness_low_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.merged_score[['betweenness_centrality', 'degree_centrality_all', 'cluster']].loc[goi_high_betweenness_low_degree].reset_index(drop=False).pivot_table(index='index', columns='cluster', values=['betweenness_centrality','degree_centrality_all'], aggfunc='first')#.sort_index(axis=1, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree centrality all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = links.merged_score[['degree_centrality_all','cluster']].reset_index(drop=False).pivot_table(index='index', columns='cluster', values='degree_centrality_all')\n",
    "df_degree_sorted = pd.DataFrame(index=range(10), columns=pd.MultiIndex.from_product([order, ['Gene', 'Degree Centrality All']]))\n",
    "for cl in order:\n",
    "    indices_for_table = df[cl].sort_values(ascending=False).index[:10]\n",
    "    df_degree_sorted[cl] = df.loc[indices_for_table, cl].reset_index().values\n",
    "df_degree_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvector centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = links.merged_score[['eigenvector_centrality', 'cluster']].reset_index(drop=False).pivot_table(index='index', columns='cluster', values='eigenvector_centrality')\n",
    "df_ev_centrality_sorted = pd.DataFrame(index=range(10), columns=pd.MultiIndex.from_product([order, ['Gene', 'Eigenvector Centrality']]))\n",
    "for cl in order:\n",
    "    indices_for_table = df[cl].sort_values(ascending=False).index[:10]\n",
    "    df_ev_centrality_sorted[cl] = df.loc[indices_for_table, cl].reset_index().values\n",
    "df_ev_centrality_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:05,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "e_vals = {}\n",
    "e_vecs = {}\n",
    "v_svd = {}\n",
    "s2_svd = {}\n",
    "ut_svd = {}\n",
    "\n",
    "for i, cell_type in tqdm(enumerate(order)):\n",
    "    e_vals[cell_type], e_vecs[cell_type] = np.linalg.eig(ls.W[cell_type])\n",
    "    v_svd[cell_type], s2_svd[cell_type], ut_svd[cell_type] = np.linalg.svd(ls.W[cell_type])\n",
    "\n",
    "## Check for the outlier eigenvalues and the corresponding eigenvectors, what genes are the predominant in the eigenvectors?\n",
    "## Check also the genes with the highest negative real part of the eigenvalues\n",
    "# Genes with the highest degradation energy per gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants and parameters\n",
    "n_genes = 20\n",
    "part = 'real'  # Can be 'real', 'imag', or 'abs'\n",
    "exclude_genes = []\n",
    "genes_in = np.where(~np.isin(ls.gene_names, exclude_genes))[0]\n",
    "\n",
    "# Get the eigenvectors sorted by eigenvalues\n",
    "df_rankings = pd.DataFrame(index=range(len(ls.gene_names)))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 64), tight_layout=True)\n",
    "gs = fig.add_gridspec(16,4)\n",
    "gene_axs = [[gs[i,j] for j in range(4)] for i in range(0,16,2)]\n",
    "total_axs = [[gs[i,j:j+2] for j in range(0,4,2)] for i in range(1,16,2)]\n",
    "\n",
    "\n",
    "for k,gene_ax,total_ax in zip(order,gene_axs,total_axs):\n",
    "    eigenvalues = e_vals[k]\n",
    "    eigenvectors = e_vecs[k][:, np.argsort(eigenvalues.real)[::-1]]\n",
    "    for eig_n,ax in enumerate(gene_ax):\n",
    "# Choose the part to plot (real, imaginary, or absolute value)\n",
    "        parts = {\n",
    "            'real': eigenvectors[:, eig_n].real,\n",
    "            'imag': eigenvectors[:, eig_n].imag,\n",
    "            'abs': np.abs(eigenvectors[:, eig_n])\n",
    "        }\n",
    "        vector_to_plot = parts[part][genes_in]\n",
    "\n",
    "    # Create the plot\n",
    "        sorted_indices = np.argsort(vector_to_plot)\n",
    "        sorted_indices_absolute = np.argsort(np.abs(vector_to_plot))[::-1]\n",
    "        indices_to_plot = sorted_indices_absolute[:n_genes]\n",
    "\n",
    "        x_data = [np.where(sorted_indices==idx)[0][0] for idx in indices_to_plot]\n",
    "        y_data = vector_to_plot[indices_to_plot]\n",
    "        names = ls.gene_names[indices_to_plot]\n",
    "\n",
    "        df_rankings[f'{k} {part} eigenvector {eig_n+1} genes'] = ls.gene_names[sorted_indices]\n",
    "        df_rankings[f'{k} {part} eigenvector {eig_n+1}'] = vector_to_plot[sorted_indices]\n",
    "\n",
    "                        \n",
    "    for par,ax in zip(['real','imag'],total_ax):\n",
    "        evecs = e_vecs[k].real if par=='real' else e_vecs[k].imag\n",
    "        evals = e_vals[k].real if par=='real' else e_vals[k].imag\n",
    "\n",
    "        e_score = evecs @ evals\n",
    "\n",
    "        sorted_indices = np.argsort(e_score)\n",
    "        sorted_indices_absolute = np.argsort(np.abs(e_score))[::-1]\n",
    "        indices_to_plot = sorted_indices_absolute[:n_genes]\n",
    "\n",
    "        df_rankings[f'{k} {par} score genes'] = ls.gene_names[sorted_indices]\n",
    "        df_rankings[f'{k} {par} score'] = e_score[sorted_indices]\n",
    "\n",
    "        x_data = [np.where(sorted_indices==idx)[0][0] for idx in indices_to_plot]\n",
    "        y_data = e_score[indices_to_plot]\n",
    "        names = ls.gene_names[indices_to_plot]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linspace_iterator(start, stop, num):\n",
    "    if num == 1:\n",
    "        yield start\n",
    "        return\n",
    "    step = (stop - start) / float(num - 1)\n",
    "    for i in range(num):\n",
    "        yield start + i * step\n",
    "\n",
    "def annotate_points(ax, x_data, y_data, labels, offset_x_fraction=0.1, offset_y_fraction=0.1):\n",
    "    n_positive = sum(y >= 0 for y in y_data)\n",
    "    n_negative = sum(y < 0 for y in y_data)\n",
    "    n_total = len(y_data) // 2\n",
    "    frac_positive = n_positive / n_total\n",
    "    frac_negative = n_negative / n_total\n",
    "    offsets_positive = linspace_iterator(-0.25 * offset_y_fraction * frac_positive, 1.75 * offset_y_fraction * frac_positive, n_positive)\n",
    "    offsets_negative = linspace_iterator(-0.25 * offset_y_fraction * frac_negative, 1.75 * offset_y_fraction * frac_negative, n_negative)\n",
    "    offset_x = offset_x_fraction\n",
    "\n",
    "    for name, x, y in zip(labels, x_data, y_data):\n",
    "        offset_y = next(offsets_positive) if y >= 0 else next(offsets_negative)\n",
    "\n",
    "        # Convert offset to display coordinates\n",
    "        offset_x_data = offset_x * ax.figure.dpi\n",
    "        offset_y_data = offset_y * ax.figure.dpi\n",
    "\n",
    "        # Determine text position based on y-value\n",
    "        if y < 0:\n",
    "            xytext = (offset_x_data, offset_y_data)\n",
    "            ha = 'left'\n",
    "        else:\n",
    "            xytext = (-offset_x_data, -offset_y_data)\n",
    "            ha = 'right'\n",
    "\n",
    "        # Annotate the point\n",
    "        ax.annotate(name, xy=(x, y), xytext=xytext, fontsize=8, ha=ha, textcoords='offset points', \n",
    "                    arrowprops=dict(arrowstyle=\"->\", color='gray', lw=0.5))\n",
    "\n",
    "# Define constants and parameters\n",
    "n_genes = 10\n",
    "n_genes_table = 100\n",
    "part = 'real'  # Can be 'real', 'imag', or 'abs'\n",
    "exclude_genes = []\n",
    "genes_in = np.where(~np.isin(ls.gene_names, exclude_genes))[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(order), 3, figsize=(15, 3 * len(order)))\n",
    "df_eigenvalues = pd.DataFrame(index=range(1,n_genes_table+1),columns=pd.MultiIndex.from_product([order, ['EV gene', 'EV value', 'Score gene', 'Score value']]))\n",
    "top_evalues = {}\n",
    "\n",
    "n_gernes = 10\n",
    "\n",
    "for i, cell_type in enumerate(order):\n",
    "    # Calculate eigenvalues and eigenvectors\n",
    "    e_vals, e_vecs = np.linalg.eig(ls.W[cell_type])\n",
    "    \n",
    "    # Plot eigenvalues (real vs imaginary)\n",
    "    ax = axs[i, 0]\n",
    "    ax.scatter(e_vals.real, e_vals.imag, label=cell_type, color=colors[cell_type])\n",
    "    ax.set_xlabel('Real part')\n",
    "    ax.set_ylabel('Imaginary part')\n",
    "    ax.legend()\n",
    "    if i == 0:\n",
    "        ax.set_title(f'Eigenvalues')\n",
    "\n",
    "    # Plot sorted eigenvector components\n",
    "    eigenvector = e_vecs[:, np.argmax(e_vals.real)]\n",
    "    top_evalues[cell_type] = e_vals[np.argmax(e_vals.real)]\n",
    "    sorted_indices_abs = np.argsort(np.abs(eigenvector))[::-1]\n",
    "    sorted_indices = np.argsort(eigenvector)\n",
    "    indices_for_table = sorted_indices_abs[:n_genes_table]\n",
    "    indices_to_plot = sorted_indices_abs[:n_genes]\n",
    "    \n",
    "    x_data = [np.where(sorted_indices==idx)[0][0] for idx in indices_to_plot]\n",
    "    y_data = eigenvector[indices_to_plot]\n",
    "    names = ls.gene_names[indices_to_plot]\n",
    "\n",
    "    df_eigenvalues[cell_type, 'EV gene'] = ls.gene_names[indices_for_table]\n",
    "    df_eigenvalues[cell_type, 'EV value'] = list(map(lambda x: f'{np.real(x):.3f}', eigenvector[indices_for_table]))\n",
    "    \n",
    "    ax = axs[i, 1]\n",
    "    ax.plot(eigenvector[sorted_indices], '.', color=colors[cell_type])\n",
    "    ax.set_ylabel('Component value')\n",
    "    annotate_points(ax, x_data, y_data, names, offset_x_fraction=0.2, offset_y_fraction=0.1)\n",
    "    ax.set_xticks([])\n",
    "    if i == 0:\n",
    "        ax.set_title(f'First Eigenvector components')\n",
    "\n",
    "    # Plot real eigenvector score sorted\n",
    "    evecs = e_vecs.real if part=='real' else e_vecs.imag\n",
    "    evals = e_vals.real if part=='real' else e_vals.imag\n",
    "\n",
    "    e_score = evecs @ evals\n",
    "\n",
    "    sorted_indices = np.argsort(e_score)\n",
    "    sorted_indices_absolute = np.argsort(np.abs(e_score))[::-1]\n",
    "    indices_to_plot = sorted_indices_absolute[:n_genes]\n",
    "    indices_for_table = sorted_indices_abs[:n_genes_table]\n",
    "\n",
    "    df_rankings[f'{cell_type} {part} score genes'] = ls.gene_names[sorted_indices]\n",
    "    df_rankings[f'{cell_type} {part} score'] = e_score[sorted_indices]\n",
    "\n",
    "    x_data = [np.where(sorted_indices==idx)[0][0] for idx in indices_to_plot]\n",
    "    y_data = e_score[indices_to_plot]\n",
    "    names = ls.gene_names[indices_to_plot]\n",
    "\n",
    "    df_eigenvalues[cell_type, 'Score gene'] = ls.gene_names[indices_for_table]\n",
    "    df_eigenvalues[cell_type, 'Score value'] = list(map(lambda x: f'{np.real(x):.3f}', e_score[indices_for_table]))\n",
    "\n",
    "    ax = axs[i, 2]\n",
    "    ax.plot(np.sort(e_score),'.',color=colors[cell_type])\n",
    "    ax.set_ylabel('Component score')\n",
    "    ax.set_xticks([])\n",
    "    annotate_points(ax, x_data, y_data, names, offset_x_fraction=0.2, offset_y_fraction=0.1)\n",
    "    if i == 0:\n",
    "        ax.set_title(f'Eigenvector score')\n",
    "\n",
    "\n",
    "# fig.savefig('../../FiguresForPaper/Eigenvectors.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_eigenvalues.loc[:, pd.MultiIndex.from_product([order, ['EV gene', 'EV value']])]\n",
    "\n",
    "# Initialize an empty DataFrame to store sorted values\n",
    "sorted_df = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "\n",
    "# Loop through each cluster (every 2 columns: \"EV gene\" and \"EV value\")\n",
    "for cluster in df.columns.levels[0]:  # Get unique cluster names\n",
    "    ev_gene_col = (cluster, \"EV gene\")   # Tuple for MultiIndex\n",
    "    ev_value_col = (cluster, \"EV value\") # Tuple for MultiIndex\n",
    "    \n",
    "    # Sort by absolute value of EV value\n",
    "    sorted_cluster = df.sort_values(by=ev_value_col, key=lambda x: abs(x.astype('float')), ascending=False)\n",
    "    \n",
    "    # Store the sorted results\n",
    "    sorted_df[ev_gene_col] = sorted_cluster[ev_gene_col].values\n",
    "    sorted_df[ev_value_col] = sorted_cluster[ev_value_col].values\n",
    "\n",
    "# Reset index to match original\n",
    "sorted_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(top_evalues)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "sorted_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(order), 3, figsize=(15, 3 * len(order)))\n",
    "df_eigenvalues_neg = pd.DataFrame(index=range(1,n_genes_table+1),columns=pd.MultiIndex.from_product([order, ['EV gene', 'EV value', 'Score gene', 'Score value']]))\n",
    "top_neg_evalues = {}\n",
    "\n",
    "n_genes = 10\n",
    "for i, cell_type in tqdm(enumerate(order)):\n",
    "    # Calculate eigenvalues and eigenvectors\n",
    "    e_vals, e_vecs = np.linalg.eig(ls.W[cell_type])\n",
    "    \n",
    "    # Plot eigenvalues (real vs imaginary)\n",
    "    ax = axs[i, 0]\n",
    "    ax.scatter(e_vals.real, e_vals.imag, label=cell_type, color=colors[cell_type])\n",
    "    ax.set_xlabel('Real part')\n",
    "    ax.set_ylabel('Imaginary part')\n",
    "    ax.legend()\n",
    "    if i == 0:\n",
    "        ax.set_title(f'Eigenvalues')\n",
    "\n",
    "    # Plot sorted eigenvector components\n",
    "    eigenvector = e_vecs[:, np.argmin(e_vals.real)]\n",
    "    top_neg_evalues[cell_type] = e_vals[np.argmin(e_vals.real)]\n",
    "    sorted_indices_abs = np.argsort(np.abs(eigenvector))[::-1]\n",
    "    sorted_indices = np.argsort(eigenvector)\n",
    "    indices_for_table = sorted_indices_abs[:n_genes_table]\n",
    "    indices_to_plot = sorted_indices_abs[:n_genes]\n",
    "    \n",
    "    x_data = [np.where(sorted_indices==idx)[0][0] for idx in indices_to_plot]\n",
    "    y_data = eigenvector[indices_to_plot]\n",
    "    names = ls.gene_names[indices_to_plot]\n",
    "\n",
    "    df_eigenvalues_neg[cell_type, 'EV gene'] = ls.gene_names[indices_for_table]\n",
    "    df_eigenvalues_neg[cell_type, 'EV value'] = list(map(lambda x: f'{np.real(x):.3f}', eigenvector[indices_for_table]))\n",
    "    \n",
    "    ax = axs[i, 1]\n",
    "    ax.plot(eigenvector[sorted_indices], '.', color=colors[cell_type])\n",
    "    ax.set_ylabel('Component value')\n",
    "    annotate_points(ax, x_data, y_data, names, offset_x_fraction=0.2, offset_y_fraction=0.1)\n",
    "    ax.set_xticks([])\n",
    "    if i == 0:\n",
    "        ax.set_title(f'First Eigenvector components')\n",
    "\n",
    "    # Plot real eigenvector score sorted\n",
    "    evecs = e_vecs.real if part=='real' else e_vecs.imag\n",
    "    evals = e_vals.real if part=='real' else e_vals.imag\n",
    "\n",
    "    e_score = evecs @ evals\n",
    "\n",
    "    sorted_indices = np.argsort(e_score)\n",
    "    sorted_indices_absolute = np.argsort(np.abs(e_score))[::-1]\n",
    "    indices_to_plot = sorted_indices_absolute[:n_genes]\n",
    "    indices_for_table = sorted_indices_abs[:n_genes_table]\n",
    "\n",
    "    df_rankings[f'{cell_type} {part} score genes'] = ls.gene_names[sorted_indices]\n",
    "    df_rankings[f'{cell_type} {part} score'] = e_score[sorted_indices]\n",
    "\n",
    "    x_data = [np.where(sorted_indices==idx)[0][0] for idx in indices_to_plot]\n",
    "    y_data = e_score[indices_to_plot]\n",
    "    names = ls.gene_names[indices_to_plot]\n",
    "\n",
    "    df_eigenvalues_neg[cell_type, 'Score gene'] = ls.gene_names[indices_for_table]\n",
    "    df_eigenvalues_neg[cell_type, 'Score value'] = list(map(lambda x: f'{np.real(x):.3f}', e_score[indices_for_table]))\n",
    "\n",
    "    ax = axs[i, 2]\n",
    "    ax.plot(np.sort(e_score),'.',color=colors[cell_type])\n",
    "    ax.set_ylabel('Component score')\n",
    "    ax.set_xticks([])\n",
    "    annotate_points(ax, x_data, y_data, names, offset_x_fraction=0.2, offset_y_fraction=0.1)\n",
    "    if i == 0:\n",
    "        ax.set_title(f'Eigenvector score')\n",
    "\n",
    "\n",
    "# fig.savefig('../../FiguresForPaper/Eigenvectors.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_eigenvalues_neg.loc[:, pd.MultiIndex.from_product([order, ['EV gene', 'EV value']])]\n",
    "\n",
    "# Initialize an empty DataFrame to store sorted values\n",
    "sorted_df = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "\n",
    "# Loop through each cluster (every 2 columns: \"EV gene\" and \"EV value\")\n",
    "for cluster in df.columns.levels[0]:  # Get unique cluster names\n",
    "    ev_gene_col = (cluster, \"EV gene\")   # Tuple for MultiIndex\n",
    "    ev_value_col = (cluster, \"EV value\") # Tuple for MultiIndex\n",
    "    \n",
    "    # Sort by absolute value of EV value\n",
    "    sorted_cluster = df.sort_values(by=ev_value_col, key=lambda x: abs(x.astype('float')), ascending=False)\n",
    "    \n",
    "    # Store the sorted results\n",
    "    sorted_df[ev_gene_col] = sorted_cluster[ev_gene_col].values\n",
    "    sorted_df[ev_value_col] = sorted_cluster[ev_value_col].values\n",
    "\n",
    "# Reset index to match original\n",
    "sorted_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(top_neg_evalues)\n",
    "sorted_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(order), 3, figsize=(16, 4 * len(order)))\n",
    "df_eigenvalues_combined = pd.DataFrame(\n",
    "    index=range(1, n_genes_table + 1),\n",
    "    columns=pd.MultiIndex.from_product(\n",
    "        [order, ['+EV gene', '+EV value', '-EV gene', '-EV value']]\n",
    "    )\n",
    ")\n",
    "\n",
    "for i, cell_type in enumerate(order):\n",
    "    W = ls.W[cell_type]\n",
    "    eigvals, eigvecs = np.linalg.eig(W)\n",
    "\n",
    "    # Get indices and eigenvalues\n",
    "    pos_idx = np.argmax(eigvals.real)\n",
    "    neg_idx = np.argmin(eigvals.real)\n",
    "    pos_val = eigvals[pos_idx]\n",
    "    neg_val = eigvals[neg_idx]\n",
    "\n",
    "    # ==== COLUMN 1: EIGENVALUE SCATTER ====\n",
    "    ax = axs[i, 0]\n",
    "    ax.scatter(eigvals.real, eigvals.imag, color=colors[cell_type], alpha=0.6, s=15)\n",
    "    ax.scatter(pos_val.real, pos_val.imag, color='blue', edgecolor='black', label='Max Re(λ)', zorder=3)\n",
    "    ax.scatter(neg_val.real, neg_val.imag, color='red', edgecolor='black', label='Min Re(λ)', zorder=3)\n",
    "    ax.set_xlabel(\"Re(λ)\")\n",
    "    ax.set_ylabel(\"Im(λ)\")\n",
    "    ax.set_title(f\"{cell_type} - Eigenvalues\")\n",
    "    ax.legend()\n",
    "\n",
    "    # ==== COLUMN 2: POSITIVE EIGENVECTOR ====\n",
    "    eigvec_pos = eigvecs[:, pos_idx]\n",
    "    sorted_indices_pos = np.argsort(eigvec_pos)\n",
    "    sorted_abs_pos = np.argsort(np.abs(eigvec_pos))[::-1]\n",
    "    indices_top_pos = sorted_abs_pos[:n_genes]\n",
    "    x_data_pos = [np.where(sorted_indices_pos == idx)[0][0] for idx in indices_top_pos]\n",
    "    y_data_pos = eigvec_pos[indices_top_pos]\n",
    "    names_pos = ls.gene_names[indices_top_pos]\n",
    "\n",
    "    ax = axs[i, 1]\n",
    "    ax.plot(eigvec_pos[sorted_indices_pos], '.', color='blue')\n",
    "    annotate_points(ax, x_data_pos, y_data_pos, names_pos, offset_y_fraction=0.1)\n",
    "    ax.set_ylabel(\"Component value\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_title(\"Top +EV vector genes\")\n",
    "\n",
    "    df_eigenvalues_combined[cell_type, '+EV gene'] = ls.gene_names[sorted_abs_pos[:n_genes_table]]\n",
    "    df_eigenvalues_combined[cell_type, '+EV value'] = [f\"{v:.3f}\" for v in eigvec_pos[sorted_abs_pos[:n_genes_table]]]\n",
    "\n",
    "    # ==== COLUMN 3: NEGATIVE EIGENVECTOR ====\n",
    "    eigvec_neg = eigvecs[:, neg_idx]\n",
    "    sorted_indices_neg = np.argsort(eigvec_neg)\n",
    "    sorted_abs_neg = np.argsort(np.abs(eigvec_neg))[::-1]\n",
    "    indices_top_neg = sorted_abs_neg[:n_genes]\n",
    "    x_data_neg = [np.where(sorted_indices_neg == idx)[0][0] for idx in indices_top_neg]\n",
    "    y_data_neg = eigvec_neg[indices_top_neg]\n",
    "    names_neg = ls.gene_names[indices_top_neg]\n",
    "\n",
    "    ax = axs[i, 2]\n",
    "    ax.plot(eigvec_neg[sorted_indices_neg], '.', color='red')\n",
    "    annotate_points(ax, x_data_neg, y_data_neg, names_neg, offset_y_fraction=0.1)\n",
    "    ax.set_ylabel(\"Component value\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_title(\"Top -EV vector genes\")\n",
    "\n",
    "    df_eigenvalues_combined[cell_type, '-EV gene'] = ls.gene_names[sorted_abs_neg[:n_genes_table]]\n",
    "    df_eigenvalues_combined[cell_type, '-EV value'] = [f\"{v:.3f}\" for v in eigvec_neg[sorted_abs_neg[:n_genes_table]]]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jacobian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION === #\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Number of cells & genes\n",
    "n_cells = ls.adata.n_obs\n",
    "n_genes = len(ls.genes)\n",
    "\n",
    "# Initialize Jacobians and Eigenvalues storage\n",
    "jacobians = {\n",
    "    'jacobians': np.zeros((n_cells, n_genes, n_genes)),\n",
    "    'eigenvalues': np.zeros((n_cells, n_genes), dtype=np.complex128),\n",
    "}\n",
    "\n",
    "# === COMPUTE FULL JACOBIANS AND EIGENVALUES === #\n",
    "for cluster_label, W_cluster in ls.W.items():\n",
    "    if cluster_label == 'all':\n",
    "        continue  # Skip general model\n",
    "\n",
    "    print(f\"Processing cluster: {cluster_label}\")\n",
    "\n",
    "    # Convert parameters to torch tensors on the correct device\n",
    "    gamma = torch.diag(torch.tensor(ls.gamma[cluster_label], dtype=torch.float32, device=device))\n",
    "    W = torch.tensor(W_cluster, dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Select relevant cluster cells\n",
    "    cluster_indices = np.where(ls.adata.obs[ls.cluster_key] == cluster_label)[0]\n",
    "    cell_data = torch.tensor(ls.adata.layers[ls.spliced_matrix_key][cluster_indices][:, ls.genes].A, device=device)\n",
    "\n",
    "    # Compute sigmoid derivative\n",
    "    exponent = torch.tensor(ls.exponent, device=device)\n",
    "    sigmoid_values = torch.tensor(ls.get_sigmoid(cell_data.cpu().numpy()), device=device)\n",
    "    sigmoid_prime = exponent * sigmoid_values * (1 - sigmoid_values) / ((1 - cell_data) * (cell_data == 0) + cell_data)\n",
    "\n",
    "    # Iterate through cells and compute Jacobians\n",
    "    for idx, sig_prime_value in tqdm(\n",
    "        zip(cluster_indices, sigmoid_prime),\n",
    "        total=len(cluster_indices),\n",
    "        desc=f\"Computing Jacobians for {cluster_label}\"\n",
    "    ):\n",
    "        jac_f = W * sig_prime_value[None, :] - gamma\n",
    "        evals = torch.linalg.eigvals(jac_f)\n",
    "\n",
    "        jacobians['jacobians'][idx] = jac_f.cpu().numpy()\n",
    "        jacobians['eigenvalues'][idx] = evals.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['evals_full'] = scp.sparse.csr_matrix(adata.layers[ls.spliced_matrix_key].shape, dtype=np.complex128)\n",
    "adata.layers['evals_full'][:,ls.genes] = jacobians['eigenvalues']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalue distribution of full Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_full_evals = adata.layers['evals_full'].A\n",
    "# fig,ax = plt.subplots(1,1,figsize=(15,5))\n",
    "# ax.set_title('Eigenvalues of the Jacobian')\n",
    "# for k in ls.W:\n",
    "#     if k=='all':\n",
    "#         continue\n",
    "#     ax.scatter(jac_full_evals[(adata.obs[cluster_key]==k).values].real.flatten(), jac_full_evals[(adata.obs[cluster_key]==k).values].imag.flatten(), label=f'{k}', color=colors[k], s=2)\n",
    "# ax.legend()\n",
    "\n",
    "# fig,axs = plt.subplots(2,4,figsize=(20,10), sharex=True, sharey=True, tight_layout=True)\n",
    "# axs = axs.flatten()\n",
    "# fig.suptitle('Real part of the eigenvalues of the Jacobian')\n",
    "# for k,ax in zip(order, axs):\n",
    "#     ax.set_title(k)\n",
    "#     sns.histplot(jac_full_evals[(adata.obs[cluster_key]==k).values].real.flatten(), ax=ax, color=colors[k], bins=100)\n",
    "#     ax.set_yscale('log')\n",
    "#     ax.text(0.1,0.9,f'Standard deviation\\n{np.std(jac_full_evals[(adata.obs[cluster_key]==k).values].real.flatten()):.2}', transform=ax.transAxes)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_full_evals = adata.layers['evals_full'].A\n",
    "fig,axs = plt.subplots(4,2,figsize=(15,15), tight_layout=True, sharex=True, sharey=True)\n",
    "ax.set_title('Eigenvalues of the Jacobian')\n",
    "for k,ax in zip(ls.W,axs.flat):\n",
    "    if k=='all':\n",
    "        continue\n",
    "    ax.scatter(jac_full_evals[(adata.obs[cluster_key]==k).values].real.flatten(), jac_full_evals[(adata.obs[cluster_key]==k).values].imag.flatten(), label=f'{k}', color=colors[k], s=2)\n",
    "    # ax.set_xlim(-20,None)\n",
    "    ax.set_title(k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal(n: int):\n",
    "    if 11 <= (n % 100) <= 13:\n",
    "        suffix = 'th'\n",
    "    else:\n",
    "        suffix = ['th', 'st', 'nd', 'rd', 'th'][min(n % 10, 4)]\n",
    "    return str(n) + suffix\n",
    "\n",
    "def plot_jacobian_eigenvalue(adata,jac_evals,n, fig_size=(17,5), name=''):\n",
    "    adata.obs['eval_real_tmp'] = np.real(jac_evals[:,n])\n",
    "    adata.obs['eval_imag_tmp'] = np.imag(jac_evals[:,n])\n",
    "    adata.obs['eval_number_tmp'] = np.sum(np.real(jac_evals)>0, axis=1)\n",
    "    adata.obs['eval_number_neg_tmp'] = np.sum(np.real(jac_evals)<0, axis=1)\n",
    "    fig,axs = plt.subplots(1,3,figsize=fig_size)\n",
    "    dyn.pl.streamline_plot(adata, basis='umap', color='eval_real_tmp', ax=axs[0], save_show_or_return='return')\n",
    "    dyn.pl.streamline_plot(adata, basis='umap', color='eval_imag_tmp', ax=axs[1], save_show_or_return='return')\n",
    "    dyn.pl.streamline_plot(adata, basis='umap', color='eval_number_tmp', ax=axs[2], save_show_or_return='return')\n",
    "    axs[0].set_title(f'{ordinal(n+1)} eigenvalue\\n{name.capitalize()} Jacobian - Real')\n",
    "    axs[1].set_title(f'{ordinal(n+1)} eigenvalue\\n{name.capitalize()} Jacobian - Imaginary')\n",
    "    axs[2].set_title(f'Number of positive eigenvalues\\n{name.capitalize()} Jacobian - Real')\n",
    "    plt.show()\n",
    "    del adata.obs['eval_real_tmp'], adata.obs['eval_imag_tmp'], adata.obs['eval_number_tmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1947, 1728)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.imag(jacobians['eigenvalues'])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['first_eval_full_real'] = np.real(jac_full_evals[:,0])\n",
    "adata.obs['first_eval_full_imag'] = np.imag(jac_full_evals[:,0])\n",
    "adata.obs['positive_evals_full_real'] = np.sum(np.real(jac_full_evals)>0, axis=1)\n",
    "adata.obs['negative_evals_full_real'] = np.sum(np.real(jac_full_evals)<0, axis=1)\n",
    "adata.obs['jacobian_trace'] = jacobians['jacobians'].trace(axis1=1, axis2=2)\n",
    "A = 0.5*(jacobians['jacobians'] - jacobians['jacobians'].transpose(0,2,1))\n",
    "adata.obs['rotational_part'] = np.linalg.norm(A, axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2,figsize=(20,15))\n",
    "axs = axs.flatten()\n",
    "# dyn.pl.streamline_plot(adata, color='first_eval_full_real', basis='umap', ax=axs[0], show_legend='on data', save_show_or_return='return')\n",
    "# dyn.pl.streamline_plot(adata, color='first_eval_full_imag', basis='umap', ax=axs[1], show_legend='on data', save_show_or_return='return')\n",
    "dyn.pl.streamline_plot(adata, color='jacobian_trace', basis='umap', ax=axs[0], show_legend='on data', save_show_or_return='return')\n",
    "dyn.pl.streamline_plot(adata, color='rotational_part', basis='umap', ax=axs[1], show_legend='on data', save_show_or_return='return')\n",
    "dyn.pl.streamline_plot(adata, color='positive_evals_full_real', basis='umap', ax=axs[2], show_legend='on data', save_show_or_return='return')\n",
    "dyn.pl.streamline_plot(adata, color='negative_evals_full_real', basis='umap', ax=axs[3], show_legend='on data', save_show_or_return='return')\n",
    "axs[0].set_title('Trace of the Jacobian')\n",
    "axs[1].set_title('Local rotational part of the Jacobian')\n",
    "axs[2].set_title('Number of positive eigenvalues\\n Jacobian - Real')\n",
    "axs[3].set_title('Number of negative eigenvalues\\n Jacobian - Real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_jacobian_eigenvalue(adata, jac_full_evals, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of positive eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[colors[i] for i in order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Real Part ---\n",
    "df_real = pd.DataFrame(jac_full_evals[:, ls.genes].real, index=adata.obs_names)\n",
    "df_real['cluster'] = adata.obs[cluster_key]\n",
    "df_real = df_real.melt(id_vars='cluster', value_name='eigenvalue').drop(columns='variable')\n",
    "df_real = df_real[df_real['eigenvalue'] > 0]\n",
    "\n",
    "# --- Imaginary Part ---\n",
    "df_imag = pd.DataFrame(jac_full_evals[:, ls.genes].imag, index=adata.obs_names)\n",
    "df_imag['cluster'] = adata.obs[cluster_key]\n",
    "df_imag = df_imag.melt(id_vars='cluster', value_name='eigenvalue').drop(columns='variable')\n",
    "df_imag = df_imag[df_imag['eigenvalue'] > 0]\n",
    "\n",
    "# --- Plot Setup ---\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15, 15), sharey=False, tight_layout=True)\n",
    "\n",
    "# Real\n",
    "sns.boxplot(\n",
    "    data=df_real, x='cluster', y='eigenvalue',\n",
    "    showfliers=False, ax=axs[0],\n",
    ")\n",
    "axs[0].set_title(\"Positive Real Part of Eigenvalues\", fontsize=14)\n",
    "axs[0].set_xlabel(\"Cluster\", fontsize=12)\n",
    "axs[0].set_ylabel(\"Eigenvalue (Real)\", fontsize=12)\n",
    "axs[0].tick_params(axis='x', rotation=45)\n",
    "axs[0].grid(axis='y', linestyle='--', alpha=0.4)\n",
    "\n",
    "# Imag\n",
    "sns.boxplot(\n",
    "    data=df_imag, x='cluster', y='eigenvalue',\n",
    "    showfliers=False, ax=axs[1],\n",
    ")\n",
    "axs[1].set_title(\"Positive Imaginary Part of Eigenvalues\", fontsize=14)\n",
    "axs[1].set_xlabel(\"Cluster\", fontsize=12)\n",
    "axs[1].set_ylabel(\"Eigenvalue (Imaginary)\", fontsize=12)\n",
    "axs[1].tick_params(axis='x', rotation=45)\n",
    "axs[1].grid(axis='y', linestyle='--', alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of number of positive eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[colors[i] for i in order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute the real part of all eigenvalues\n",
    "df_evals_real = pd.DataFrame(jac_full_evals[:, ls.genes].real, index=adata.obs_names)\n",
    "\n",
    "# Step 2: Count positive eigenvalues per cell\n",
    "pos_counts = (df_evals_real > 0).sum(axis=1)\n",
    "\n",
    "# Step 3: Add cluster info\n",
    "pos_counts = pos_counts.to_frame(name='positive_eigen_count')\n",
    "pos_counts['cluster'] = adata.obs[cluster_key].values\n",
    "\n",
    "# Step 4: Plot distribution\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(data=pos_counts, x='cluster', y='positive_eigen_count', showfliers=True, order=order)\n",
    "plt.ylabel(\"Number of Positive Real Eigenvalues\")\n",
    "plt.title(\"Distribution of Positive Eigenvalue Counts per Cell Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace (divergence) and Vorticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_divergence_vorticity = ls.adata.obs[['jacobian_trace','rotational_part',ls.cluster_key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jacobian_trace</th>\n",
       "      <th>rotational_part</th>\n",
       "      <th>cell_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CCACAAGCGTGC-JL12_0</th>\n",
       "      <td>-287.281633</td>\n",
       "      <td>12.800689</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCATCCTGTGGA-JL12_0</th>\n",
       "      <td>-295.101246</td>\n",
       "      <td>43.490254</td>\n",
       "      <td>Meg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCCTCGGCCGCA-JL12_0</th>\n",
       "      <td>-288.236061</td>\n",
       "      <td>16.298562</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCGCCCACCATG-JL12_0</th>\n",
       "      <td>-283.560082</td>\n",
       "      <td>13.970761</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCGCTGTGTAAG-JL12_0</th>\n",
       "      <td>-293.742051</td>\n",
       "      <td>7.467204</td>\n",
       "      <td>MEP-like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTGAACCTGTGA-JL12_1</th>\n",
       "      <td>-286.986476</td>\n",
       "      <td>12.901093</td>\n",
       "      <td>MEP-like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTGAGACAATAC-JL12_1</th>\n",
       "      <td>-293.809392</td>\n",
       "      <td>6.929403</td>\n",
       "      <td>MEP-like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTGATATTGACC-JL12_1</th>\n",
       "      <td>-295.050628</td>\n",
       "      <td>8.790370</td>\n",
       "      <td>MEP-like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTGCCGCGACAA-JL12_1</th>\n",
       "      <td>-298.979089</td>\n",
       "      <td>17.625506</td>\n",
       "      <td>Bas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTGTGCATTCCT-JL12_1</th>\n",
       "      <td>-293.738365</td>\n",
       "      <td>13.395640</td>\n",
       "      <td>Ery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1947 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     jacobian_trace  rotational_part cell_type\n",
       "barcode                                                       \n",
       "CCACAAGCGTGC-JL12_0     -287.281633        12.800689       Mon\n",
       "CCATCCTGTGGA-JL12_0     -295.101246        43.490254       Meg\n",
       "CCCTCGGCCGCA-JL12_0     -288.236061        16.298562       Mon\n",
       "CCGCCCACCATG-JL12_0     -283.560082        13.970761       Mon\n",
       "CCGCTGTGTAAG-JL12_0     -293.742051         7.467204  MEP-like\n",
       "...                             ...              ...       ...\n",
       "GTGAACCTGTGA-JL12_1     -286.986476        12.901093  MEP-like\n",
       "GTGAGACAATAC-JL12_1     -293.809392         6.929403  MEP-like\n",
       "GTGATATTGACC-JL12_1     -295.050628         8.790370  MEP-like\n",
       "GTGCCGCGACAA-JL12_1     -298.979089        17.625506       Bas\n",
       "GTGTGCATTCCT-JL12_1     -293.738365        13.395640       Ery\n",
       "\n",
       "[1947 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_divergence_vorticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute the real part of all eigenvalues\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[colors[i] for i in order])\n",
    "df_divergence_vorticity = ls.adata.obs[['jacobian_trace','rotational_part',ls.cluster_key]]\n",
    "\n",
    "# Step 4: Plot distribution\n",
    "fig,axs = plt.subplots(2, 1, figsize=(15, 15))\n",
    "sns.boxplot(data=df_divergence_vorticity, x=ls.cluster_key, y='jacobian_trace', showfliers=False, order=order, ax=axs[0])\n",
    "sns.boxplot(data=df_divergence_vorticity, x=ls.cluster_key, y='rotational_part', showfliers=False, order=order, ax=axs[1])\n",
    "axs[0].set_ylabel(\"Trace of the Jacobian\")\n",
    "axs[1].set_ylabel(\"Rotational part of the Jacobian\")\n",
    "axs[0].set_title(\"Distribution of Jacobian Trace per Cell Type\")\n",
    "axs[1].set_title(\"Distribution of Jacobian Rotational Part per Cell Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamplot_eig_n(adata, eig_n, jacobian='diffusion', part='real', ax=None, **kwargs):\n",
    "    figsize = kwargs.get('figsize',(15,10))\n",
    "    cmap = kwargs.get('cmap','viridis')\n",
    "    _,ax = plt.subplots(1, 1, figsize=figsize) if ax is None else (None,ax)\n",
    "    part = np.real if part=='real' else np.imag\n",
    "    adata.obs[f'Eigenvalue {eig_n+1}'] = part(adata.layers[f'evals_{jacobian}'][:,adata.var['use_for_dynamics'].values][:,eig_n].A.flatten())\n",
    "    _ = dyn.pl.streamline_plot(adata, color=f'Eigenvalue {eig_n+1}', basis='umap', size=(15,10), show_legend='on data', cmap=cmap, show_arrowed_spines=True, ax=ax, save_show_or_return='return')\n",
    "    # plt.show()\n",
    "    del adata.obs[f'Eigenvalue {eig_n+1}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(5,4,figsize=(15,15))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    streamplot_eig_n(adata, i, jacobian='full', cmap='coolwarm', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamo figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_gata1 = ls.adata.var.index.get_indexer_for(['GATA1'])[0]\n",
    "index_gata2 = ls.adata.var.index.get_indexer_for(['GATA2'])[0]\n",
    "index_fli1 = ls.adata.var.index.get_indexer_for(['FLI1'])[0]\n",
    "index_cebpa = ls.adata.var.index.get_indexer_for(['CEBPA'])[0]\n",
    "index_runx1 = ls.adata.var.index.get_indexer_for(['RUNX1'])[0]\n",
    "index_klf1 = ls.adata.var.index.get_indexer_for(['KLF1'])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobians clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.adata.obs[r'$\\frac{df_{{FLI1}}}{dx_{{KLF1}}}$'] = jacobians['jacobians'][:,index_fli1,index_klf1]\n",
    "ls.adata.obs[r'$\\frac{df_{KLF1}}{dx_{FLI1}}$'] = jacobians['jacobians'][:,index_klf1,index_fli1]\n",
    "ls.adata.obs[r'$\\frac{df_{FLI1}}{dx_{FLI1}}$'] = jacobians['jacobians'][:,index_fli1,index_fli1]\n",
    "ls.adata.obs[r'$\\frac{df_{KLF1}}{dx_{KLF1}}$'] = jacobians['jacobians'][:,index_klf1,index_klf1]\n",
    "\n",
    "ls.adata.obs[r'$\\frac{df_{GATA1}}{dx_{GATA2}}$'] = jacobians['jacobians'][:,index_gata1,index_gata2]\n",
    "ls.adata.obs[r'$\\frac{df_{GATA2}}{dx_{GATA1}}$'] = jacobians['jacobians'][:,index_gata2,index_gata1]\n",
    "ls.adata.obs[r'$\\frac{df_{GATA1}}{dx_{KLF1}}$'] = jacobians['jacobians'][:,index_gata1,index_klf1]\n",
    "ls.adata.obs[r'$\\frac{df_{KLF1}}{dx_{GATA1}}$'] = jacobians['jacobians'][:,index_klf1,index_gata1]\n",
    "ls.adata.obs[r'$\\frac{df_{GATA1}}{dx_{FLI1}}$'] = jacobians['jacobians'][:,index_gata1,index_fli1]\n",
    "ls.adata.obs[r'$\\frac{df_{FLI1}}{dx_{GATA1}}$'] = jacobians['jacobians'][:,index_fli1,index_gata1]\n",
    "\n",
    "ls.adata.obs[r'$\\frac{df_{CEBPA}}{dx_{RUNX1}}$'] = jacobians['jacobians'][:,index_cebpa,index_runx1]\n",
    "ls.adata.obs[r'$\\frac{df_{RUNX1}}{dx_{CEBPA}}$'] = jacobians['jacobians'][:,index_runx1,index_cebpa]\n",
    "ls.adata.obs[r'$\\frac{df_{CEBPA}}{dx_{GATA2}}$'] = jacobians['jacobians'][:,index_cebpa,index_gata2]\n",
    "ls.adata.obs[r'$\\frac{df_{GATA2}}{dx_{CEBPA}}$'] = jacobians['jacobians'][:,index_gata2,index_cebpa]\n",
    "\n",
    "ls.adata.obs[r'$\\frac{df_{GATA2}}{dx_{RUNX1}}$'] = jacobians['jacobians'][:,index_gata2,index_runx1]\n",
    "ls.adata.obs[r'$\\frac{df_{RUNX1}}{dx_{GATA2}}$'] = jacobians['jacobians'][:,index_runx1,index_gata2]\n",
    "ls.adata.obs[r'$\\frac{df_{GATA2}}{dx_{GATA2}}$'] = jacobians['jacobians'][:,index_gata2,index_gata2]\n",
    "ls.adata.obs[r'$\\frac{df_{RUNX1}}{dx_{RUNX1}}$'] = jacobians['jacobians'][:,index_runx1,index_runx1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2,figsize=(10,10))\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{{FLI1}}}{dx_{{KLF1}}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{KLF1}}{dx_{FLI1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[1,0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{FLI1}}{dx_{FLI1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,1], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{KLF1}}{dx_{KLF1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[1,1], sym_c=True)\n",
    "# plt.delaxes(axs[1,1])\n",
    "\n",
    "fig,axs = plt.subplots(2,3,figsize=(15,10))\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{GATA1}}{dx_{GATA2}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{GATA2}}{dx_{GATA1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[1,0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{GATA1}}{dx_{KLF1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,1], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{KLF1}}{dx_{GATA1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[1,1], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{GATA1}}{dx_{FLI1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,2], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{FLI1}}{dx_{GATA1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[1,2], sym_c=True)\n",
    "\n",
    "fig,axs = plt.subplots(2,2,figsize=(10,10))\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{CEBPA}}{dx_{RUNX1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{RUNX1}}{dx_{CEBPA}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[1,0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{CEBPA}}{dx_{GATA2}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,1], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{GATA2}}{dx_{CEBPA}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[1,1], sym_c=True)\n",
    "\n",
    "fig,axs = plt.subplots(2,2,figsize=(10,10))\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{GATA2}}{dx_{RUNX1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{RUNX1}}{dx_{GATA2}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[1,0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{GATA2}}{dx_{GATA2}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,1], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{RUNX1}}{dx_{RUNX1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='show', ax=axs[1,1], sym_c=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks with prevalent genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Colormap, LinearSegmentedColormap\n",
    "\n",
    "def GRN_graph(\n",
    "    ls, W1, genes, merged_scores, \n",
    "    score_size=None, size_threshold=0, score_color=None, cmap=None,  \n",
    "    topn=None, ax=None, w_quantile=0.99\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a Gene Regulatory Network (GRN) graph.\n",
    "\n",
    "    Args:\n",
    "        ls (object): Object containing `gene_names`.\n",
    "        W1 (np.ndarray): Weighted adjacency matrix of interactions.\n",
    "        genes (list): List of gene names.\n",
    "        merged_scores (pd.DataFrame): Dataframe containing gene scores.\n",
    "        score_size (str, optional): Column in `merged_scores` to use for node sizes. Defaults to None.\n",
    "        size_threshold (float, optional): Threshold for displaying node labels. Defaults to 0.\n",
    "        score_color (str, optional): Not currently used. Defaults to None.\n",
    "        cmap (str or Colormap, optional): Colormap for edge coloring. Defaults to None.\n",
    "        topn (int, optional): Number of top genes to retain based on size. Defaults to None.\n",
    "        ax (matplotlib.axes.Axes, optional): Axis for plotting. Defaults to None.\n",
    "        w_quantile (float, optional): Quantile threshold for filtering weak edges. Defaults to 0.99.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays a network plot.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy matrix to avoid modifying original data\n",
    "    W = W1.copy()\n",
    "    \n",
    "    # Threshold edges based on weight quantile\n",
    "    threshold = np.quantile(abs(W), w_quantile)\n",
    "    W[abs(W) < threshold] = 0\n",
    "\n",
    "    # Create DataFrame representation\n",
    "    df = pd.DataFrame(W, index=ls.gene_names, columns=ls.gene_names).T\n",
    "\n",
    "    # Compute node sizes\n",
    "    if score_size is None:\n",
    "        sizes = abs(W).sum(axis=0) + abs(W).sum(axis=1)\n",
    "    else:\n",
    "        sizes = np.array([\n",
    "            merged_scores.loc[g, score_size] if g in merged_scores.index else 0 \n",
    "            for g in df.index\n",
    "        ])\n",
    "\n",
    "    # Filter top genes based on size\n",
    "    topq = np.sort(sizes)[-topn] if topn is not None else 0\n",
    "    dropids = df.index[sizes < topq]\n",
    "    \n",
    "    # Normalize sizes for better visualization\n",
    "    size_multiplier = 1000 / max(sizes) if max(sizes) > 0 else 1\n",
    "    sizes = sizes[ls.gene_names.isin(genes)]\n",
    "    sizes = size_multiplier * sizes[sizes >= topq]\n",
    "    \n",
    "    # Remove genes below threshold\n",
    "    genes = [g for g in genes if g not in dropids]\n",
    "    df.drop(index=dropids, columns=dropids, inplace=True)\n",
    "    df = df[genes].loc[genes]\n",
    "\n",
    "    # Define node labels (hide small ones)\n",
    "    labels = {\n",
    "        gene: gene if size / 1000 > size_threshold else ''\n",
    "        for gene, size in zip(df.index, sizes)\n",
    "    }\n",
    "\n",
    "    # Create directed graph\n",
    "    G = nx.from_pandas_adjacency(df, create_using=nx.DiGraph)\n",
    "    Gp = nx.from_pandas_adjacency(abs(df), create_using=nx.DiGraph)\n",
    "\n",
    "    # Compute edge weights for visualization\n",
    "    weights = np.array([abs(G[u][v]['weight']) for u, v in G.edges()])\n",
    "    weights_signed = 10 * np.array([G[u][v]['weight'] for u, v in G.edges()])\n",
    "    weights = 1.5 * np.log(1 + weights) / np.log(1 + max(weights)) if weights.size else weights\n",
    "\n",
    "    # Define node positions\n",
    "    pos = nx.circular_layout(G)  # Alternative: nx.spring_layout(Gp), nx.kamada_kawai_layout(Gp)\n",
    "\n",
    "    # Define axes\n",
    "    ax = ax or plt.figure(figsize=(10, 10)).gca()\n",
    "\n",
    "    # Validate colormap input\n",
    "    if isinstance(cmap, str):\n",
    "        cmap = plt.get_cmap(cmap) if cmap is not None else plt.cm.viridis\n",
    "    elif not isinstance(cmap, Colormap):\n",
    "        raise ValueError(\"`cmap` must be a string or a matplotlib.colors.Colormap instance\")\n",
    "\n",
    "    # Compute colormap normalization\n",
    "    vmax = max(weights) if weights.size else 1\n",
    "\n",
    "    # Draw network graph\n",
    "    nx.draw_networkx(\n",
    "        G, pos, node_size=sizes, width=weights, with_labels=True, labels=labels,\n",
    "        edge_color=weights_signed, edge_cmap=cmap, edge_vmin=-vmax, edge_vmax=vmax, ax=ax\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Colormap\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "def plot_subset_grn(\n",
    "    ls, W1, selected_genes, merged_scores, \n",
    "    score_size=None, ax=None, node_positions=None,\n",
    "    prune_threshold=0, selected_edges=None, \n",
    "    node_color='white', label_offset=0.11, label_size=12,\n",
    "    variable_width = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a Gene Regulatory Network (GRN) for a user-defined subset of genes.\n",
    "\n",
    "    Args:\n",
    "        ls (object): Object containing `gene_names`.\n",
    "        W1 (np.ndarray): Weighted adjacency matrix of interactions.\n",
    "        selected_genes (list): List of genes to include in the graph.\n",
    "        merged_scores (pd.DataFrame): DataFrame containing gene scores.\n",
    "        score_size (str, optional): Column in `merged_scores` to use for node sizes. Defaults to None.\n",
    "        ax (matplotlib.axes.Axes, optional): Axis for plotting. Defaults to None.\n",
    "        node_positions (dict, optional): Dictionary with custom node positions.\n",
    "        prune_threshold (float, optional): Edges below this threshold (absolute value) will be removed.\n",
    "        selected_edges (list of tuples, optional): List of user-defined edges (tuples) to plot.\n",
    "        node_color (str, optional): Color of nodes. Default is `\"skyblue\"`.\n",
    "        label_offset (float, optional): Distance of labels from nodes. Default is `0.15`.\n",
    "        label_size (int, optional): Font size for labels. Default is `12`.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays a network plot.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert adjacency matrix to DataFrame\n",
    "    df = pd.DataFrame(W1, index=ls.gene_names, columns=ls.gene_names).T\n",
    "\n",
    "    # Subset the graph to only the selected nodes\n",
    "    df = df.loc[selected_genes, selected_genes]\n",
    "\n",
    "    # **Prune weak edges**\n",
    "    df[abs(df) < prune_threshold] = 0  \n",
    "\n",
    "    # **Filter only user-defined edges (if provided)**\n",
    "    if selected_edges:\n",
    "        mask = np.zeros_like(df, dtype=bool)\n",
    "        for u, v in selected_edges:\n",
    "            if u in df.index and v in df.columns:\n",
    "                mask[df.index.get_loc(u), df.columns.get_loc(v)] = True\n",
    "        df[~mask] = 0  # Keep only selected edges\n",
    "\n",
    "    # Compute node sizes\n",
    "    if score_size is None:\n",
    "        sizes = abs(df).sum(axis=0) + abs(df).sum(axis=1)\n",
    "    else:\n",
    "        sizes = np.array([\n",
    "            merged_scores.loc[g, score_size] if g in merged_scores.index else 0 \n",
    "            for g in selected_genes\n",
    "        ])\n",
    "\n",
    "    # Normalize sizes\n",
    "    size_multiplier = 1000 / max(sizes) if max(sizes) > 0 else 1\n",
    "    sizes = size_multiplier * sizes\n",
    "    node_size_dict = {node: size for node, size in zip(selected_genes, sizes)}\n",
    "\n",
    "    # Define node labels\n",
    "    labels = {gene: gene for gene in selected_genes}\n",
    "\n",
    "    # Create directed graph\n",
    "    G = nx.from_pandas_adjacency(df, create_using=nx.DiGraph)\n",
    "\n",
    "    # Compute edge weights\n",
    "    edge_list = [(u, v) for u, v in G.edges() if abs(G[u][v]['weight']) >= prune_threshold]\n",
    "    weights = np.array([abs(G[u][v]['weight']) for u, v in edge_list])\n",
    "    weights_signed = np.array([G[u][v]['weight'] for u, v in edge_list])\n",
    "\n",
    "    # Normalize edge widths\n",
    "    weights = 2 * np.log1p(weights) / np.log1p(weights.max()) if weights.size else weights\n",
    "\n",
    "    # Use predefined node positions if provided, otherwise default to spring layout\n",
    "    pos = {gene: node_positions[gene] for gene in selected_genes if gene in node_positions} if node_positions else {}\n",
    "    if len(pos) < len(selected_genes):\n",
    "        default_layout = nx.spring_layout(G)\n",
    "        for node in selected_genes:\n",
    "            if node not in pos:\n",
    "                pos[node] = default_layout[node]\n",
    "\n",
    "    # Define axes\n",
    "    ax = ax or plt.figure(figsize=(10, 10)).gca()\n",
    "\n",
    "    # Set fixed edge colors (Red for positive, Blue for negative)\n",
    "    edge_colors = ['red' if w > 0 else 'blue' for w in weights_signed]\n",
    "\n",
    "    # Handle bidirectional edges: shift arcs slightly to avoid overlap\n",
    "    curved_edges = set()\n",
    "    for u, v in edge_list:\n",
    "        if u == v:\n",
    "            continue\n",
    "        if (v, u) in edge_list and (v, u) not in curved_edges:\n",
    "            curved_edges.add((u, v))\n",
    "            curved_edges.add((v, u))\n",
    "\n",
    "    # # **Calculate dynamic arrow size based on node size**\n",
    "    # min_arrow_size = 15\n",
    "    # max_arrow_size = 35\n",
    "    # arrow_sizes = np.clip(weights * 10, min_arrow_size, max_arrow_size)\n",
    "\n",
    "    # **Adjust margins for each node**\n",
    "    min_margin = 0.02\n",
    "    max_margin = 0.1\n",
    "    node_margins = {node: np.clip(size / 2000, min_margin, max_margin) for node, size in node_size_dict.items()}\n",
    "\n",
    "    # **First, draw edges BELOW nodes (background)**\n",
    "    # nx.draw_networkx_edges(G, pos, edgelist=edge_list, width=weights, edge_color=edge_colors, \n",
    "    #                        ax=ax, alpha=0.4, connectionstyle=\"arc3,rad=0.1\")\n",
    "\n",
    "    # **Then, draw nodes (foreground)**\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=sizes, node_color=node_color, edgecolors='black', linewidths=1.5, ax=ax, alpha=0.9)\n",
    "\n",
    "    # **Move labels outside the nodes**\n",
    "    adjusted_pos = {k: (v[0], v[1] + label_offset) for k, v in pos.items()}\n",
    "    nx.draw_networkx_labels(G, adjusted_pos, labels, font_size=label_size, ax=ax)\n",
    "\n",
    "    # **Finally, draw edges ABOVE nodes with adjusted arrows**\n",
    "    for edge in edge_list:\n",
    "        u, v = edge\n",
    "        edge_idx = edge_list.index(edge)\n",
    "        width = weights[edge_idx] if variable_width else 1\n",
    "        style = \"arc3,rad=0.15\" if edge in curved_edges else \"arc3,rad=0\"\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=[edge], width=width,\n",
    "                               edge_color=[edge_colors[edge_idx]], ax=ax, \n",
    "                               arrows=True, #arrowsize=arrow_sizes[edge_idx], \n",
    "                               min_source_margin=node_margins.get(u, min_margin), \n",
    "                               min_target_margin=node_margins.get(v, min_margin), \n",
    "                               connectionstyle=style)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure from Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_graph = [\"blue\", \"lightgray\", \"red\"]\n",
    "positions = [0, 0.5, 1]  # Must range from 0 to 1\n",
    "# Step 2: Create the colormap\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", list(zip(positions, colors_graph)))\n",
    "\n",
    "k = 'Ductal'\n",
    "fig,axs = plt.subplots(4,2, figsize=(20,40),tight_layout=True)\n",
    "score = 'degree_centrality_out'\n",
    "# score = 'degree_centrality_in'\n",
    "# score = 'eigenvector_centrality'\n",
    "score_names = ['degree_all', 'degree_centrality_all', 'degree_in', 'degree_centrality_in', 'degree_out', 'degree_centrality_out', 'betweenness_centrality', 'eigenvector_centrality']\n",
    "score = score_names[5]\n",
    "topn = 50\n",
    "\n",
    "for k,ax in zip(links.cluster, axs.flat):\n",
    "    ax.axis('off')\n",
    "    ax.set_title(score.capitalize().replace('_',' ') + ' - ' + k)\n",
    "\n",
    "\n",
    "    GRN_graph(ls, ls.W[k],ls.gene_names, links.merged_score[links.merged_score.cluster==k], score_size=score, cmap=custom_cmap, size_threshold=0.25, topn=topn, ax=ax)\n",
    "    # GRN_graph(ls.W[k],ls.gene_names, links.entropy[links.entropy.cluster==k], score_size=score, cmap=custom_cmap, size_threshold=0.025, topn=topn, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(4,2, figsize=(20,15),tight_layout=True)\n",
    "score = 'degree_centrality_out'\n",
    "# score = 'degree_centrality_in'\n",
    "# score = 'eigenvector_centrality'\n",
    "score_names = ['degree_all', 'degree_centrality_all', 'degree_in', 'degree_centrality_in', 'degree_out', 'degree_centrality_out', 'betweenness_centrality', 'eigenvector_centrality']\n",
    "\n",
    "custom_positions = {\n",
    "    'CEBPA': (1,1), 'GATA1': (4,1), 'GATA2': (0,0), \n",
    "    'RUNX1': (2,0), 'KLF1': (3,0), 'FLI1': (5,0)\n",
    "}\n",
    "\n",
    "selected_edeges = [('CEBPA','GATA2'), ('CEBPA','RUNX1'),\n",
    "                   ('GATA2','GATA2'), ('GATA2','RUNX1'), ('GATA2','GATA1'), ('RUNX1','GATA2'), ('RUNX1','RUNX1'),\n",
    "                   ('GATA1', 'KLF1'), ('GATA1','FLI1'), ('GATA1','GATA2'),\n",
    "                   ('KLF1', 'FLI1'), ('FLI1', 'KLF1'), ('FLI1', 'FLI1')\n",
    "                   ]\n",
    "\n",
    "for k,ax in zip(links.cluster, axs.flat):\n",
    "    ax.axis('off')\n",
    "    ax.set_title(score.capitalize().replace('_',' ') + ' - ' + k)\n",
    "\n",
    "    plot_subset_grn(ls, ls.W[k], custom_positions.keys(), links.merged_score[links.merged_score.cluster==k], score_size=score, ax=ax, node_positions=custom_positions, selected_edges=selected_edeges, label_offset=0.08, variable_width=True)\n",
    "    # GRN_graph(ls.W[k],ls.gene_names, links.entropy[links.entropy.cluster==k], score_size=score, cmap=custom_cmap, size_threshold=0.025, topn=topn, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure from Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1947, 1728, 1728)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians['jacobians'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_jacobian = {}\n",
    "for k in order:\n",
    "    cell_idx = np.where(adata.obs[cluster_key] == k)[0]\n",
    "    mean_jacobian[k] = np.mean(jacobians['jacobians'][cell_idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_graph = [\"blue\", \"lightgray\", \"red\"]\n",
    "positions = [0, 0.5, 1]  # Must range from 0 to 1\n",
    "# Step 2: Create the colormap\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", list(zip(positions, colors_graph)))\n",
    "\n",
    "k = 'Ductal'\n",
    "fig,axs = plt.subplots(4,2, figsize=(20,40),tight_layout=True)\n",
    "score = 'degree_centrality_out'\n",
    "# score = 'degree_centrality_in'\n",
    "# score = 'eigenvector_centrality'\n",
    "score_names = ['degree_all', 'degree_centrality_all', 'degree_in', 'degree_centrality_in', 'degree_out', 'degree_centrality_out', 'betweenness_centrality', 'eigenvector_centrality']\n",
    "score = score_names[5]\n",
    "topn = 50\n",
    "\n",
    "for k,ax in zip(links.cluster, axs.flat):\n",
    "    ax.axis('off')\n",
    "    ax.set_title(score.capitalize().replace('_',' ') + ' - ' + k)\n",
    "\n",
    "\n",
    "    GRN_graph(ls, mean_jacobian[k],ls.gene_names, links.merged_score[links.merged_score.cluster==k], score_size=None, cmap=custom_cmap, size_threshold=0.25, topn=topn, ax=ax)\n",
    "    # GRN_graph(ls.W[k],ls.gene_names, links.entropy[links.entropy.cluster==k], score_size=score, cmap=custom_cmap, size_threshold=0.025, topn=topn, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(4,2, figsize=(20,15),tight_layout=True)\n",
    "score = 'degree_centrality_out'\n",
    "# score = 'degree_centrality_in'\n",
    "# score = 'eigenvector_centrality'\n",
    "score_names = ['degree_all', 'degree_centrality_all', 'degree_in', 'degree_centrality_in', 'degree_out', 'degree_centrality_out', 'betweenness_centrality', 'eigenvector_centrality']\n",
    "\n",
    "custom_positions = {\n",
    "    'CEBPA': (1,1), 'GATA1': (4,1), 'GATA2': (0,0), \n",
    "    'RUNX1': (2,0), 'KLF1': (3,0), 'FLI1': (5,0)\n",
    "}\n",
    "\n",
    "selected_edeges = [('CEBPA','GATA2'), ('CEBPA','RUNX1'),\n",
    "                   ('GATA2','GATA2'), ('GATA2','RUNX1'), ('GATA2','GATA1'), ('RUNX1','GATA2'), ('RUNX1','RUNX1'),\n",
    "                   ('GATA1', 'KLF1'), ('GATA1','FLI1'), ('GATA1','GATA2'),\n",
    "                   ('KLF1', 'FLI1'), ('FLI1', 'KLF1'), ('FLI1', 'FLI1')\n",
    "                   ]\n",
    "\n",
    "for k,ax in zip(links.cluster, axs.flat):\n",
    "    ax.axis('off')\n",
    "    ax.set_title(score.capitalize().replace('_',' ') + ' - ' + k)\n",
    "\n",
    "    plot_subset_grn(ls, mean_jacobian[k], custom_positions.keys(), links.merged_score[links.merged_score.cluster==k], score_size=None, ax=ax, node_positions=custom_positions, selected_edges=selected_edeges, label_offset=0.08, variable_width=True)\n",
    "    # GRN_graph(ls.W[k],ls.gene_names, links.entropy[links.entropy.cluster==k], score_size=score, cmap=custom_cmap, size_threshold=0.025, topn=topn, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLI1 - KLF1 exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(10,5))\n",
    "dyn.pl.scatters(ls.adata, color='FLI1', basis='umap', show_legend='on data', cmap='viridis', save_show_or_return='return', ax=axs[0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color='KLF1', basis='umap', show_legend='on data', cmap='viridis', save_show_or_return='return', ax=axs[1], sym_c=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2,figsize=(10,10))\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{{FLI1}}}{dx_{{KLF1}}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{KLF1}}{dx_{FLI1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[1,0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{FLI1}}{dx_{FLI1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,1], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{KLF1}}{dx_{KLF1}}$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[1,1], sym_c=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.adata.obs[r'$\\frac{df_{{FLI1}}}{dx_{{KLF1}}}\\times KLF1$'] = jacobians['jacobians'][:,index_fli1,index_klf1] * ls.adata.layers[ls.spliced_matrix_key][:,index_klf1].A.flatten()\n",
    "ls.adata.obs[r'$\\frac{df_{KLF1}}{dx_{FLI1}}\\times FLI1$'] = jacobians['jacobians'][:,index_klf1,index_fli1] * ls.adata.layers[ls.spliced_matrix_key][:,index_fli1].A.flatten()\n",
    "ls.adata.obs[r'$\\frac{df_{FLI1}}{dx_{FLI1}}\\times FLI1$'] = jacobians['jacobians'][:,index_fli1,index_fli1] * ls.adata.layers[ls.spliced_matrix_key][:,index_fli1].A.flatten()\n",
    "ls.adata.obs[r'$\\frac{df_{KLF1}}{dx_{KLF1}}\\times KLF1$'] = jacobians['jacobians'][:,index_klf1,index_klf1] * ls.adata.layers[ls.spliced_matrix_key][:,index_klf1].A.flatten()\n",
    "\n",
    "\n",
    "fig,axs = plt.subplots(2,2,figsize=(20,15))\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{{FLI1}}}{dx_{{KLF1}}}\\times KLF1$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{KLF1}}{dx_{FLI1}}\\times FLI1$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[1,0], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{FLI1}}{dx_{FLI1}}\\times FLI1$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[0,1], sym_c=True)\n",
    "dyn.pl.scatters(ls.adata, color=r'$\\frac{df_{KLF1}}{dx_{KLF1}}\\times KLF1$', basis='umap', show_legend='on data', cmap='coolwarm', save_show_or_return='return', ax=axs[1,1], sym_c=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effective effect network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(4,2, figsize=(10,8),tight_layout=True)\n",
    "score = 'degree_centrality_out'\n",
    "# score = 'degree_centrality_in'\n",
    "# score = 'eigenvector_centrality'\n",
    "score_names = ['degree_all', 'degree_centrality_all', 'degree_in', 'degree_centrality_in', 'degree_out', 'degree_centrality_out', 'betweenness_centrality', 'eigenvector_centrality']\n",
    "\n",
    "custom_positions = {\n",
    "    'KLF1': (0,0), 'FLI1': (1,0)\n",
    "}\n",
    "# selected_edeges = [('CEBPA','GATA2'), ('CEBPA','RUNX1'),\n",
    "#                    ('GATA2','GATA2'), ('GATA2','RUNX1'), ('GATA2','GATA1'), ('RUNX1','GATA2'), ('RUNX1','RUNX1'),\n",
    "#                    ('GATA1', 'KLF1'), ('GATA1','FLI1'), ('GATA1','GATA2'),\n",
    "#                    ('KLF1', 'FLI1'), ('FLI1', 'KLF1'), ('FLI1', 'FLI1')\n",
    "#                    ]\n",
    "\n",
    "for k,ax in zip(links.cluster, axs.flat):\n",
    "    ax.axis('off')\n",
    "    ax.set_title(score.capitalize().replace('_',' ') + ' - ' + k)\n",
    "    # W = -jacobians['jacobians'][ls.adata.obs[cluster_key] == k].mean(axis=0)\n",
    "    W = jacobians['jacobians'][ls.adata.obs[cluster_key] == k]\n",
    "    W[:,:,index_klf1] = W[:,:,index_klf1] * ls.adata.layers[ls.spliced_matrix_key][ls.adata.obs[cluster_key] == k][:,index_klf1].A.flatten()[:,None]\n",
    "    W[:,:,index_fli1] = W[:,:,index_fli1] * ls.adata.layers[ls.spliced_matrix_key][ls.adata.obs[cluster_key] == k][:,index_fli1].A.flatten()[:,None]\n",
    "    W = W.mean(axis=0)\n",
    "    plot_subset_grn(ls, W, custom_positions.keys(), links.merged_score[links.merged_score.cluster==k], score_size=score, ax=ax, node_positions=custom_positions, label_offset=0.08, variable_width=True)\n",
    "    # GRN_graph(ls.W[k],ls.gene_names, links.entropy[links.entropy.cluster==k], score_size=score, cmap=custom_cmap, size_threshold=0.025, topn=topn, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobian network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(4,2, figsize=(10,8),tight_layout=True)\n",
    "score = 'degree_centrality_out'\n",
    "# score = 'degree_centrality_in'\n",
    "# score = 'eigenvector_centrality'\n",
    "score_names = ['degree_all', 'degree_centrality_all', 'degree_in', 'degree_centrality_in', 'degree_out', 'degree_centrality_out', 'betweenness_centrality', 'eigenvector_centrality']\n",
    "\n",
    "custom_positions = {\n",
    "    'KLF1': (0,0), 'FLI1': (1,0)\n",
    "}\n",
    "# selected_edeges = [('CEBPA','GATA2'), ('CEBPA','RUNX1'),\n",
    "#                    ('GATA2','GATA2'), ('GATA2','RUNX1'), ('GATA2','GATA1'), ('RUNX1','GATA2'), ('RUNX1','RUNX1'),\n",
    "#                    ('GATA1', 'KLF1'), ('GATA1','FLI1'), ('GATA1','GATA2'),\n",
    "#                    ('KLF1', 'FLI1'), ('FLI1', 'KLF1'), ('FLI1', 'FLI1')\n",
    "#                    ]\n",
    "\n",
    "for k,ax in zip(links.cluster, axs.flat):\n",
    "    ax.axis('off')\n",
    "    ax.set_title(score.capitalize().replace('_',' ') + ' - ' + k)\n",
    "    # W = -jacobians['jacobians'][ls.adata.obs[cluster_key] == k].mean(axis=0)\n",
    "    W = -jacobians['jacobians'][ls.adata.obs[cluster_key] == k]\n",
    "    W = W.mean(axis=0)\n",
    "    plot_subset_grn(ls, W, custom_positions.keys(), links.merged_score[links.merged_score.cluster==k], score_size=score, ax=ax, node_positions=custom_positions, label_offset=0.08, variable_width=True)\n",
    "    # GRN_graph(ls.W[k],ls.gene_names, links.entropy[links.entropy.cluster==k], score_size=score, cmap=custom_cmap, size_threshold=0.025, topn=topn, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(4,2, figsize=(10,8),tight_layout=True)\n",
    "score = 'degree_centrality_out'\n",
    "# score = 'degree_centrality_in'\n",
    "# score = 'eigenvector_centrality'\n",
    "score_names = ['degree_all', 'degree_centrality_all', 'degree_in', 'degree_centrality_in', 'degree_out', 'degree_centrality_out', 'betweenness_centrality', 'eigenvector_centrality']\n",
    "\n",
    "custom_positions = {\n",
    "    'KLF1': (0,0), 'FLI1': (1,0)\n",
    "}\n",
    "# selected_edeges = [('CEBPA','GATA2'), ('CEBPA','RUNX1'),\n",
    "#                    ('GATA2','GATA2'), ('GATA2','RUNX1'), ('GATA2','GATA1'), ('RUNX1','GATA2'), ('RUNX1','RUNX1'),\n",
    "#                    ('GATA1', 'KLF1'), ('GATA1','FLI1'), ('GATA1','GATA2'),\n",
    "#                    ('KLF1', 'FLI1'), ('FLI1', 'KLF1'), ('FLI1', 'FLI1')\n",
    "#                    ]\n",
    "\n",
    "for k,ax in zip(links.cluster, axs.flat):\n",
    "    ax.axis('off')\n",
    "    ax.set_title(score.capitalize().replace('_',' ') + ' - ' + k)\n",
    "    plot_subset_grn(ls, ls.W[k], custom_positions.keys(), links.merged_score[links.merged_score.cluster==k], score_size=score, ax=ax, node_positions=custom_positions, label_offset=0.08, variable_width=True)\n",
    "    # GRN_graph(ls.W[k],ls.gene_names, links.entropy[links.entropy.cluster==k], score_size=score, cmap=custom_cmap, size_threshold=0.025, topn=topn, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCH",
   "language": "python",
   "name": "sch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
